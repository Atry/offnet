{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                       \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                       \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                          \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.lwjgl:lwjgl:3.1.2`\n",
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "import $ivy.`com.thoughtworks.compute::opencl:0.1.0`\n",
    "import $ivy.`com.dongxiguo::fastring:0.3.1`\n",
    "import $ivy.`com.thoughtworks.raii::asynchronoussemaphore:2.1.0-RC0`\n",
    "import $ivy.`eu.timepit::refined:0.8.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mammonite.ops._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.channels._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.StandardOpenOption\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ammonite.ops._\n",
    "import java.io._\n",
    "import java.nio.channels._\n",
    "import java.nio.file.StandardOpenOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mLwjglRuntimeUrl\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnet\u001b[39m.\u001b[32mURL\u001b[39m = https://repo1.maven.org/maven2/org/lwjgl/lwjgl/3.1.2/lwjgl-3.1.2-natives-linux.jar"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LwjglRuntimeUrl = {\n",
    "    import java.net._\n",
    "    val lwjglClassifier = if (util.Properties.isMac) {\n",
    "        \"natives-macos\"\n",
    "    } else if (util.Properties.osName.startsWith(\"Linux\")) {\n",
    "        \"natives-linux\"\n",
    "    } else if (util.Properties.isWin) {\n",
    "        \"natives-windows\"\n",
    "    } else {\n",
    "        throw new Exception(s\"lwjgl does not support ${util.Properties.osName}\")\n",
    "    }\n",
    "    new URL(s\"https://repo1.maven.org/maven2/org/lwjgl/lwjgl/3.1.2/lwjgl-3.1.2-$lwjglClassifier.jar\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Workaround for https://github.com/jupyter-scala/jupyter-scala/issues/128\n",
    "interp.load.cp {\n",
    "    val temporaryJar = tmp()\n",
    "    val httpStream = LwjglRuntimeUrl.openStream()\n",
    "    try {\n",
    "        val httpChannel = Channels.newChannel(httpStream)\n",
    "        try {\n",
    "            val fileChannel = FileChannel.open(temporaryJar.toNIO, StandardOpenOption.WRITE)\n",
    "            try {\n",
    "                fileChannel.transferFrom(httpChannel, 0, Long.MaxValue)\n",
    "            } finally {\n",
    "                fileChannel.close()\n",
    "            }\n",
    "        } finally {\n",
    "            httpChannel.close()\n",
    "        }\n",
    "    } finally {\n",
    "        httpStream.close()\n",
    "    }\n",
    "    temporaryJar\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// import $ivy.`com.thoughtworks.compute::opencl:0.1.0`\n",
    "// import $ivy.`com.thoughtworks.raii::asynchronoussemaphore:2.1.0-RC0`\n",
    "\n",
    "// interp.load.cp(Seq(\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/AsynchronousSemaphore/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/asynchronous/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/shared/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/covariant/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/OpenCLCodeGenerator/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/Memory/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/OpenCL/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/Closeables/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scalaz/scalaz-core_2.12/bundles/scalaz-core_2.12-7.2.14.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.continuation/continuation_2.12/jars/continuation_2.12-1.1.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.chuusai/shapeless_2.12/bundles/shapeless_2.12-2.3.2.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.typelevel/macro-compat_2.12/jars/macro-compat_2.12-1.1.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.tryt/covariant_2.12/jars/covariant_2.12-2.0.3.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.future/future_2.12/jars/future_2.12-1.1.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(s\".ivy2/cache/org.lwjgl/lwjgl/jars/lwjgl-3.1.2-${lwjglClassifier}.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.dongxiguo/fastring_2.12/jars/fastring_2.12-0.3.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scala-lang/scala-reflect/jars/scala-reflect-2.12.3.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.lwjgl/lwjgl-opencl/jars/lwjgl-opencl-3.1.2.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/eu.timepit/refined_2.12/jars/refined_2.12-0.8.2.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scala-lang/scala-compiler/jars/scala-compiler-2.12.3.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scala-lang.modules/scala-xml_2.12/bundles/scala-xml_2.12-1.0.6.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.each/each_2.12/jars/each_2.12-3.3.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.sde/core_2.12/jars/core_2.12-3.3.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scalaz/scalaz-effect_2.12/bundles/scalaz-effect_2.12-7.2.7.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.sde/comprehension-monad_2.12/jars/comprehension-monad_2.12-3.3.1.jar\")\n",
    "// ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.continuation._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.dongxiguo.fastring.Fastring.Implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.dongxiguo.fastring.Fastring\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36meu.timepit.refined.api.Refined\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36meu.timepit.refined.numeric.{Negative, Positive}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.lwjgl.opencl._, CL10._, CL12._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.lwjgl.system.MemoryUtil\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.compute.Memory.Address\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.compute.OpenCL.CommandQueue.GlobalWorkSizeOnlyDimension\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.compute.OpenCL\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.thoughtworks.continuation._\n",
    "import com.thoughtworks.future._\n",
    "\n",
    "import com.dongxiguo.fastring.Fastring.Implicits._\n",
    "import com.dongxiguo.fastring.Fastring\n",
    "import eu.timepit.refined.api.Refined\n",
    "import eu.timepit.refined.numeric.{Negative, Positive}\n",
    "\n",
    "import org.lwjgl.opencl._, CL10._, CL12._\n",
    "import org.lwjgl.system.MemoryUtil\n",
    "\n",
    "import com.thoughtworks.compute.Memory.Address\n",
    "import com.thoughtworks.compute.OpenCL.CommandQueue.GlobalWorkSizeOnlyDimension\n",
    "import com.thoughtworks.compute.OpenCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mplatform\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mPlatform\u001b[39m = \u001b[33mPlatform\u001b[39m(\u001b[32m139826283062392L\u001b[39m, org.lwjgl.opencl.CLCapabilities@4830fc99)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val platform = OpenCL.platforms.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdevice\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mDevice\u001b[39m = \u001b[33mDevice\u001b[39m(\u001b[32m139822795939088L\u001b[39m, org.lwjgl.opencl.CLCapabilities@5db61470)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val device = platform.devices.maxBy { device =>\n",
    "  Seq(CL_DEVICE_TYPE_CPU, CL_DEVICE_TYPE_GPU, CL_DEVICE_TYPE_ACCELERATOR).indexOf(device.deviceType)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontext\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mContext\u001b[39m = com.thoughtworks.compute.OpenCL$Context@29038c48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val context = platform.createContext({ (errorInfo, data) =>\n",
    "  publish.stderr(errorInfo)\n",
    "}, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcommandQueue\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mCommandQueue\u001b[39m = com.thoughtworks.compute.OpenCL$CommandQueue@2156be43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val commandQueue = context.createCommandQueue(\n",
    "    device,\n",
    "    Map(\n",
    "        CL_QUEUE_PROPERTIES -> (CL_QUEUE_OUT_OF_ORDER_EXEC_MODE_ENABLE & device.queueProperties)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mFiber\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "  * @note [[outputCellIndex]] must be greater than [[inputCellIndex]] for now. The limitation will be removed in future version\n",
    "  */\n",
    "final case class Fiber(offsetX: Int, offsetY: Int, inputCellIndex: Int, outputCellIndex: Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfInputChannels\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfInputChannels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfHiddenCells\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m100\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfHiddenCells = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfClasses\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfClasses = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfCells\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m113\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfCells = NumberOfInputChannels + NumberOfHiddenCells + NumberOfClasses // Must larger than NumberOfInputChannels + NumberOfClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mWidth\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Width = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mHeight\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Height = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mBatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m128\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val BatchSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfVotesRequiredForLabelClass\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m100\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfVotesRequiredForLabelClass = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mLearningRate\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m3.0E-7\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LearningRate = 0.0000003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mL2Regularization\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.01\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val L2Regularization = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minputFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mFiber\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputFibers = for {\n",
    "    outputCellIndex <- 3 until NumberOfCells\n",
    "    inputCellIndex <- 0 until NumberOfInputChannels\n",
    "    offsetX <- -3 to 3\n",
    "    offsetY <- -3 to 3\n",
    "    if math.random < math.pow(offsetX * offsetX + offsetY * offsetY + 1, -1.3) * math.max(0.003, 1.0 - outputCellIndex / 0.2 / NumberOfCells)\n",
    "} yield Fiber(offsetX, offsetY, inputCellIndex, outputCellIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msparseFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mFiber\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m-6\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-4\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m7\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m7\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparseFibers = for {\n",
    "    outputCellIndex <- 3 until NumberOfCells\n",
    "    inputCellIndex <- Iterator.iterate(outputCellIndex.toDouble)(_ * math.random * 0.7)\n",
    "                         .takeWhile(_ > 0.5)\n",
    "                         .map { i => outputCellIndex - math.ceil(i).toInt }\n",
    "} yield Fiber((util.Random.nextGaussian * 2).toInt, (util.Random.nextGaussian * 3).toInt, inputCellIndex, outputCellIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moffsetFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mSeqView\u001b[39m[\u001b[32mFiber\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32m_\u001b[39m]] = \u001b[33mSeqView\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m4\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m5\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val offsetFibers = (inputFibers.view ++ sparseFibers).map { fiber =>\n",
    "    def randomOffset() = {\n",
    "      (util.Random.nextGaussian() * 3).toInt\n",
    "    }\n",
    "    @scala.annotation.tailrec\n",
    "    def retry: Fiber = {\n",
    "        val randomOffsetX = (util.Random.nextGaussian() * 2).toInt\n",
    "        val randomOffsetY = (util.Random.nextGaussian() * 2).toInt\n",
    "        if (randomOffsetX == 0 && randomOffsetY == 0) {\n",
    "            retry\n",
    "        } else {\n",
    "            Fiber(fiber.offsetX + randomOffsetX, fiber.offsetY + randomOffsetY, fiber.inputCellIndex, fiber.outputCellIndex)\n",
    "        }\n",
    "    }\n",
    "    retry\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mmutable\u001b[39m.\u001b[32mArraySeq\u001b[39m[\u001b[32mFiber\u001b[39m] = \u001b[33mArraySeq\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fibers = (offsetFibers ++ inputFibers ++ sparseFibers).distinct.to[scala.collection.mutable.ArraySeq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfibersByOutputCellIndex\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mInt\u001b[39m, \u001b[32mcollection\u001b[39m.\u001b[32mSeqView\u001b[39m[(\u001b[32mFiber\u001b[39m, \u001b[32mInt\u001b[39m), \u001b[32mcollection\u001b[39m.\u001b[32mmutable\u001b[39m.\u001b[32mSeq\u001b[39m[\u001b[32m_\u001b[39m]]] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m69\u001b[39m -> \u001b[33mSeqView\u001b[39m(\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m388\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m60\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m389\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m67\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m390\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m989\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m60\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m990\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m67\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m991\u001b[39m)\n",
       "  ),\n",
       "  \u001b[32m101\u001b[39m -> \u001b[33mSeqView\u001b[39m(\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m101\u001b[39m), \u001b[32m548\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m79\u001b[39m, \u001b[32m101\u001b[39m), \u001b[32m549\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fibersByOutputCellIndex = fibers.view.zipWithIndex.groupBy(_._1.outputCellIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfibersByInputCellIndex\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mInt\u001b[39m, \u001b[32mcollection\u001b[39m.\u001b[32mSeqView\u001b[39m[(\u001b[32mFiber\u001b[39m, \u001b[32mInt\u001b[39m), \u001b[32mcollection\u001b[39m.\u001b[32mmutable\u001b[39m.\u001b[32mSeq\u001b[39m[\u001b[32m_\u001b[39m]]] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m69\u001b[39m -> \u001b[33mSeqView\u001b[39m(\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m70\u001b[39m), \u001b[32m395\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m71\u001b[39m), \u001b[32m399\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m72\u001b[39m), \u001b[32m402\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m76\u001b[39m), \u001b[32m424\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-4\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m105\u001b[39m), \u001b[32m567\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m70\u001b[39m), \u001b[32m996\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m71\u001b[39m), \u001b[32m1000\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m72\u001b[39m), \u001b[32m1003\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m76\u001b[39m), \u001b[32m1024\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m105\u001b[39m), \u001b[32m1167\u001b[39m)\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fibersByInputCellIndex = fibers.view.zipWithIndex.groupBy(_._1.inputCellIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mforwardCode\u001b[39m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forwardCode = fastraw\"\"\"\n",
    "    struct forward_fiber {\n",
    "        short offset_x;\n",
    "        short offset_y;\n",
    "        unsigned short input_cell_index;\n",
    "        unsigned short weight_index;\n",
    "    };\n",
    "    \n",
    "    float convolution(size_t image_index,\n",
    "                      size_t output_x,\n",
    "                      size_t output_y,\n",
    "                      global float* data,\n",
    "                      global float* weight,\n",
    "                      const size_t number_of_fibers,\n",
    "                      constant struct forward_fiber* forward_fibers) {\n",
    "        float output_data = 0.0f;\n",
    "        for (size_t i = 0; i < number_of_fibers; i++) {\n",
    "            struct forward_fiber fiber = forward_fibers[i];\n",
    "            ptrdiff_t offset_x = fiber.offset_x;\n",
    "            ptrdiff_t offset_y = fiber.offset_y;\n",
    "            ptrdiff_t input_x = output_x + offset_x;\n",
    "            ptrdiff_t input_y = output_y + offset_y;\n",
    "            if (\n",
    "                input_x >= 0 &&\n",
    "                input_x < $Width &&\n",
    "                input_y >= 0 &&\n",
    "                input_y < $Height\n",
    "            ) {\n",
    "                size_t input_cell_index = fiber.input_cell_index;\n",
    "                size_t weight_index = fiber.weight_index;\n",
    "                float input_data = data[\n",
    "                    input_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    input_y * $Width +\n",
    "                    input_x\n",
    "                ];\n",
    "                output_data += weight[weight_index] * input_data;\n",
    "            }\n",
    "        }\n",
    "        return output_data;\n",
    "    }\n",
    "    kernel void forward(global float* data,\n",
    "                        global float* weight,\n",
    "                        global float* bias,\n",
    "                        const size_t output_cell_index,\n",
    "                        const size_t number_of_fibers,\n",
    "                        constant struct forward_fiber* forward_fibers) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        size_t output_x = get_global_id(1);\n",
    "        size_t output_y = get_global_id(2);\n",
    "        data[\n",
    "            output_cell_index * ${Width * Height * BatchSize} +\n",
    "            image_index * ${Width * Height} +\n",
    "            output_y * $Width + output_x\n",
    "        ] = fmax(convolution(image_index, output_x, output_y, data, weight, number_of_fibers, forward_fibers) + bias[output_cell_index], 0.0f);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`backward_fiber` is a fiber from input's view. The `offset_x` and `offset_y` is always the negative value of the corresonding `forward_fiber`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mnormalizeWeight\u001b[39m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeWeight = fastraw\"\"\"\n",
    "    kernel void normalize_weight(global float* data, global float* weight, const size_t output_cell_index, const size_t number_of_fibers)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mbackwardCode\u001b[39m"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backwardCode = fastraw\"\"\"\n",
    "    struct backward_fiber {\n",
    "        short offset_x;\n",
    "        short offset_y;\n",
    "        unsigned short output_cell_index;\n",
    "        unsigned short weight_index;\n",
    "    };\n",
    "\n",
    "    kernel void backward(global float* delta,\n",
    "                         global float* weight,\n",
    "                         const size_t input_cell_index,\n",
    "                         const size_t number_of_fibers,\n",
    "                         constant struct backward_fiber* backward_fibers) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        size_t input_x = get_global_id(1);\n",
    "        size_t input_y = get_global_id(2);\n",
    "        float input_delta = 0.0f;\n",
    "        for (size_t i = 0; i < number_of_fibers; i++) {\n",
    "            struct backward_fiber fiber = backward_fibers[i];\n",
    "            ptrdiff_t offset_x = fiber.offset_x;\n",
    "            ptrdiff_t offset_y = fiber.offset_y;\n",
    "            ptrdiff_t output_x = input_x + offset_x;\n",
    "            ptrdiff_t output_y = input_y + offset_y;\n",
    "            if (\n",
    "                output_x >= 0 &&\n",
    "                output_x < $Width &&\n",
    "                output_y >= 0 &&\n",
    "                output_y < $Height\n",
    "            ) {\n",
    "                size_t output_cell_index = fiber.output_cell_index;\n",
    "                size_t weight_index = fiber.weight_index;\n",
    "                float output_delta = delta[\n",
    "                    output_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    output_y * $Width +\n",
    "                    output_x\n",
    "                ];\n",
    "                input_delta += weight[weight_index] * output_delta;\n",
    "            }\n",
    "        }\n",
    "        delta[\n",
    "            input_cell_index * ${Width * Height * BatchSize} +\n",
    "            image_index * ${Width * Height} +\n",
    "            input_y * $Width + input_x\n",
    "        ] = input_delta;\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupdateBiasCode\u001b[39m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def updateBiasCode = fastraw\"\"\"\n",
    "    kernel void update_bias(global float* delta, global float* bias) {\n",
    "        size_t cell_index = get_global_id(0);\n",
    "        float accumulator = 0.0;\n",
    "        for (size_t i = 0; i < ${BatchSize * Width * Height}; i++) {\n",
    "            accumulator += delta[cell_index * ${BatchSize * Width * Height} + i];\n",
    "        }\n",
    "        float old_bias = bias[cell_index];\n",
    "        bias[cell_index] = old_bias - (accumulator - old_bias * $L2Regularization) * $LearningRate;\n",
    "        write_mem_fence(CLK_GLOBAL_MEM_FENCE);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupdateWeightCode\u001b[39m"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def updateWeightCode = fastraw\"\"\"\n",
    "    struct plain_fiber {\n",
    "        short offset_x;\n",
    "        short offset_y;\n",
    "        unsigned short input_cell_index;\n",
    "        unsigned short output_cell_index;\n",
    "    };\n",
    "    kernel void update_weight(global float* data, global float* delta, global float* weight, global struct plain_fiber* fibers) {\n",
    "        size_t i = get_global_id(0);\n",
    "        struct plain_fiber fiber = fibers[i];\n",
    "        size_t offset_x = fiber.offset_x;\n",
    "        size_t offset_y = fiber.offset_y;\n",
    "        size_t input_cell_index = fiber.input_cell_index;\n",
    "        size_t output_cell_index = fiber.output_cell_index;\n",
    "        size_t input_cell_start = input_cell_index * ${Width * Height * BatchSize};\n",
    "        size_t output_cell_start = output_cell_index * ${Width * Height * BatchSize};\n",
    "        float delta_weight = 0.0;\n",
    "        for (size_t image_index = 0; image_index < $BatchSize; image_index++) {\n",
    "            size_t input_image_start = input_cell_start + image_index * ${Width * Height};\n",
    "            size_t output_image_start = output_cell_start + image_index * ${Width * Height};\n",
    "            for (size_t input_y = 0; input_y < $Width; input_y++) {\n",
    "                if (input_y >= offset_y) {\n",
    "                    size_t output_y = input_y - offset_y;\n",
    "                    if (output_y < $Height) {\n",
    "                        size_t input_row_start = input_image_start + input_y * $Width;\n",
    "                        size_t output_row_start = output_image_start + output_y * $Width;\n",
    "                        for (size_t input_x = 0; input_x < $Width; input_x++) {\n",
    "                            if (input_x >= offset_x) {\n",
    "                                size_t output_x = input_x - offset_x;\n",
    "                                if (output_x < $Width) {\n",
    "                                    delta_weight += data[input_row_start + input_x] *\n",
    "                                                   delta[output_row_start + output_x];\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "        }\n",
    "        float old_weight = weight[i];\n",
    "        weight[i] = old_weight - (delta_weight - old_weight * $L2Regularization) * $LearningRate;\n",
    "        write_mem_fence(CLK_GLOBAL_MEM_FENCE);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainLossCode\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainLossCode = {\n",
    "    def incorrectClasses = {\n",
    "        {\n",
    "            for (classIndex <- 0 until NumberOfClasses) yield fastraw\"\"\"\n",
    "                size_t image_start_$classIndex = ${classIndex * BatchSize * Width * Height} + image_index * ${Width * Height};\n",
    "                unsigned short class_votes_$classIndex = 0;\n",
    "                for (size_t xy = 0; xy < ${Width * Height}; xy++) {\n",
    "                    float pixel_score = score_data[image_start_$classIndex + xy];\n",
    "                    if (pixel_score > 0.0) {\n",
    "                        class_votes_$classIndex += 1;\n",
    "                        if ($classIndex != label) {\n",
    "                            image_total_loss += pixel_score;\n",
    "                            score_delta[image_start_$classIndex + xy] = ${1.0 / (Width * Height * BatchSize)};\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                if (class_votes_$classIndex >= image_max_votes) {\n",
    "                    image_max_votes = class_votes_$classIndex;\n",
    "                    output_label = $classIndex;\n",
    "                }\n",
    "            \"\"\"\n",
    "        }.mkFastring(\"\\n\")\n",
    "    }\n",
    "    def correctClass = {\n",
    "        fastraw\"\"\"\n",
    "            size_t correct_image_start = label * ${BatchSize * Width * Height} + image_index * ${Width * Height};\n",
    "            unsigned short number_of_votes = 0;\n",
    "            for (size_t xy = 0; xy < ${Width * Height}; xy++) {\n",
    "                if (score_data[correct_image_start + xy] >= 2.0) {\n",
    "                    number_of_votes += 1;\n",
    "                }\n",
    "            }\n",
    "            if (number_of_votes < $NumberOfVotesRequiredForLabelClass) {\n",
    "                for (size_t xy = 0; xy < ${Width * Height}; xy++) {\n",
    "                    float pixel_score = 2.0 - score_data[correct_image_start + xy];\n",
    "                    if (pixel_score > 0.0) {\n",
    "                        image_total_loss += ${(NumberOfClasses - 1) * 0.5} * pixel_score;\n",
    "                        score_delta[correct_image_start + xy] = ${-(NumberOfClasses - 1) * 0.5 / (Width * Height * BatchSize)};\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "    }\n",
    "    fastraw\"\"\"\n",
    "        kernel void train_loss(global float* score_data,\n",
    "                               global float* score_delta,\n",
    "                               constant unsigned char* labels,\n",
    "                               global unsigned char* output_labels,\n",
    "                               global float* loss) {\n",
    "            size_t image_index = get_global_id(0);\n",
    "            size_t label = labels[image_index];\n",
    "            float image_total_loss = 0.0;\n",
    "            unsigned short image_max_votes = 0;\n",
    "            unsigned char output_label = 0;\n",
    "            $correctClass\n",
    "            $incorrectClasses\n",
    "            loss[image_index] = image_total_loss / ${Width * Height};\n",
    "            output_labels[image_index] = output_label;\n",
    "            write_mem_fence(CLK_GLOBAL_MEM_FENCE);\n",
    "        }\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mweightInitializationCode\u001b[39m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weightInitializationCode = raw\"\"\"\n",
    "    kernel void forward_sum(global float* data,\n",
    "                            global float* weight,\n",
    "                            global float* bias,\n",
    "                            const size_t output_cell_index,\n",
    "                            const size_t number_of_fibers,\n",
    "                            constant struct forward_fiber* forward_fibers,\n",
    "                            global float* sum_of_image) {\n",
    "//         ptrdiff_t image_index = get_global_id(0);\n",
    "//         ptrdiff_t output_x = get_global_id(1);\n",
    "//         ptrdiff_t output_y = get_global_id(2);\n",
    "//         float raw_output = convolution(image_index, output_x, output_y, data, weight, number_of_fibers, forward_fibers);\n",
    "//         data[\n",
    "//             output_cell_index * ${Width * Height * BatchSize} +\n",
    "//             image_index * ${Width * Height} +\n",
    "//             output_y * $Width + output_x\n",
    "//         ] = fmax( + bias[output_cell_index], 0.0f);\n",
    "        size_t image_index = get_global_id(0);\n",
    "        float sum = 0.0f;\n",
    "        for (ptrdiff_t output_y = 0; output_y < $Height; output_y++) {\n",
    "            for (ptrdiff_t output_x = 0; output_x < $Width; output_x++) {\n",
    "                float raw_output = convolution(image_index, output_x, output_y, data, weight, number_of_fibers, forward_fibers)\n",
    "                data[\n",
    "                    output_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    output_y * $Width + output_x\n",
    "                ] = raw_output;\n",
    "                sum += raw_output;\n",
    "            }\n",
    "        }\n",
    "        sum_of_image[image_index] = sum\n",
    "    }\n",
    "    \n",
    "    kernel void square_sum(global float* data,\n",
    "                           const float mean,\n",
    "                           const size_t output_cell_index,\n",
    "                           global float* square_sum_of_image) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        float sum = 0.0f;\n",
    "        for (ptrdiff_t output_y = 0; output_y < $Height; output_y++) {\n",
    "            for (ptrdiff_t output_x = 0; output_x < $Width; output_x++) {\n",
    "                float biased_output = data[\n",
    "                    output_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    output_y * $Width + output_x\n",
    "                ] - mean;\n",
    "                sum += biased_output * biased_output;\n",
    "            }\n",
    "        }\n",
    "        square_sum_of_image[image_index] = sum;\n",
    "    }\n",
    "    \n",
    "    kernel void adjust_weight(global float* weight,\n",
    "                              global float* variance,\n",
    "                              global struct plain_fiber* fibers) {\n",
    "        size_t fiber_index = get_global_id(0);\n",
    "        struct plain_fiber fiber = fibers[weight_index];\n",
    "        weight[weight_index] /= variance[fiber.output_cell_index];\n",
    "    }\n",
    "    \n",
    "    kernel void adjust_output(global float* data,\n",
    "                              const size_t output_cell_index,\n",
    "                              const float variance,\n",
    "                              const float mean) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        size_t output_x = get_global_id(1);\n",
    "        size_t output_y = get_global_id(2);\n",
    "        size_t i = output_cell_index * ${Width * Height * BatchSize} +\n",
    "                   image_index * ${Width * Height} +\n",
    "                   output_y * $Width + output_x;\n",
    "        data[i] = (data[i] - mean) * variance;\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcode\u001b[39m: \u001b[32mFastring\u001b[39m = \u001b[33mcmd34Wrapper.Helper\u001b[39m(\n",
       "  \u001b[32m\"\"\"\n",
       "  \n",
       "    \n",
       "  \"\"\"\u001b[39m,\n",
       "  \u001b[32m\"\"\"\n",
       "  \n",
       "    struct forward_fiber {  \n",
       "        short offset_x;  \n",
       "        short offset_y;  \n",
       "        unsigned short input_cell_index;  \n",
       "        unsigned short weight_index;  \n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mprogram\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mProgram\u001b[39m = com.thoughtworks.compute.OpenCL$Program@500dbcde"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val code = fastraw\"\"\"\n",
    "    $forwardCode\n",
    "    $backwardCode\n",
    "    $updateWeightCode\n",
    "    $updateBiasCode\n",
    "    $trainLossCode\n",
    "    $weightInitializationCode\n",
    "\"\"\"\n",
    "val program = context.createProgramWithSource(code)\n",
    "program.build().blockingAwait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.net.URL\n",
    "import java.io.File\n",
    "import $ivy.`org.rauschig:jarchivelib:0.7.1`\n",
    "import org.rauschig.jarchivelib.{Archiver, ArchiverFactory}\n",
    "import java.nio.channels._\n",
    "import java.nio.file._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val Cifar10Url = new URL(\"http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\")\n",
    "val CifarDirectory = new File(\"cifar-10-batches-bin\")\n",
    "if (!CifarDirectory.exists) {\n",
    "    import sys.process._\n",
    "    val targzFile = File.createTempFile(\"cifar-10-binary\", \".tar.gz\")\n",
    "    val cifarHttpStream = Cifar10Url.openStream()\n",
    "    try {\n",
    "        val httpChannel = Channels.newChannel(cifarHttpStream)\n",
    "        try {\n",
    "            val fileChannel = FileChannel.open(targzFile.toPath, StandardOpenOption.WRITE)\n",
    "            try {\n",
    "                fileChannel.transferFrom(httpChannel, 0, Long.MaxValue)\n",
    "            } finally {\n",
    "                fileChannel.close()\n",
    "            }\n",
    "        } finally {\n",
    "            httpChannel.close()\n",
    "        }\n",
    "    } finally {\n",
    "        cifarHttpStream.close()\n",
    "    }\n",
    "    val archiver: Archiver = ArchiverFactory.createArchiver(\"tar\", \"gz\")\n",
    "    archiver.extract(targzFile, new File(sys.props(\"user.dir\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val NumberOfTrainingSamplesPerFile = 10000\n",
    "val NumberOfTrainingFiles = 5\n",
    "val NumberOfTrainingSamples = NumberOfTrainingFiles * NumberOfTrainingSamplesPerFile\n",
    "\n",
    "import java.nio.channels.FileChannel\n",
    "import java.nio.file.Paths\n",
    "import java.nio.file.Path\n",
    "import java.nio.file.StandardOpenOption\n",
    "\n",
    "val trainingHostBuffers = for (i <- 1 to NumberOfTrainingFiles) yield {\n",
    "    val batchPath = CifarDirectory.toPath.resolve(s\"data_batch_$i.bin\")\n",
    "    val channel = FileChannel.open(batchPath, StandardOpenOption.READ)\n",
    "    try {\n",
    "        channel.map(FileChannel.MapMode.READ_ONLY, 0L, channel.size)\n",
    "    } finally {\n",
    "        channel.close()\n",
    "    }\n",
    "}\n",
    "\n",
    "val testHostBuffer = {\n",
    "    val batchPath = CifarDirectory.toPath.resolve(s\"test_batch.bin\")\n",
    "    val channel = FileChannel.open(batchPath, StandardOpenOption.READ)\n",
    "    try {\n",
    "        channel.map(FileChannel.MapMode.READ_ONLY, 0L, channel.size)\n",
    "    } finally {\n",
    "        channel.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize * Width * Height * NumberOfCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val deltaDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize * Width * Height * NumberOfCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val biasDeviceBuffer = context.createUninitializedBuffer[Float](NumberOfCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeBiasBuffer() = {\n",
    "    val biasHostBuffer = MemoryUtil.memAllocFloat(NumberOfCells)\n",
    "    for (i <- 0 until NumberOfCells) {\n",
    "        biasHostBuffer.put(i, util.Random.nextFloat() * 0.00001f)\n",
    "    }\n",
    "    val event = commandQueue.enqueueWriteBuffer(biasDeviceBuffer, biasHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeBiasBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val weightDeviceBuffer = context.createUninitializedBuffer[Float](fibers.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val weightHostBuffer = MemoryUtil.memAllocFloat(fibers.length)\n",
    "def writeWeightBuffer() = {\n",
    "    for ((outputCellIndex, fibers) <- fibersByOutputCellIndex) {\n",
    "        val standardDeviation = math.sqrt(fibers.length / 2.0)\n",
    "        for ((fiber, fiberIndex) <- fibers) {\n",
    "            val initialValue = (util.Random.nextGaussian() / standardDeviation).toFloat\n",
    "            weightHostBuffer.put(fiberIndex, initialValue)\n",
    "        }\n",
    "    }\n",
    "    val event = commandQueue.enqueueWriteBuffer(weightDeviceBuffer, weightHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeWeightBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val inputDeviceBuffer = dataDeviceBuffer.view(0, BatchSize * Width * Height * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val scoreDataDeviceBuffer = dataDeviceBuffer.view(BatchSize * Width * Height * (NumberOfCells - NumberOfClasses), BatchSize * Width * Height * NumberOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val scoreDeltaDeviceBuffer = deltaDeviceBuffer.view(BatchSize * Width * Height * (NumberOfCells - NumberOfClasses), BatchSize * Width * Height * NumberOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val lossDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val predictionDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val labelDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val outputLabelDeviceBuffer = context.createUninitializedBuffer[Byte](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val epochIndices = util.Random.shuffle(0 until NumberOfTrainingSamples: IndexedSeq[Int]).grouped(BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val batchIndices = epochIndices.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val inputHostBuffer = MemoryUtil.memAllocFloat(inputDeviceBuffer.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val labelHostBuffer = MemoryUtil.memAllocFloat(labelDeviceBuffer.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillImageHostBuffer(): Unit = {\n",
    "    val imageSize = 1 + Width * Height * NumberOfInputChannels\n",
    "    val imageArray = Array.ofDim[Byte](imageSize)\n",
    "    val channelArray = Array.ofDim[Float](Width * Height)\n",
    "    for ((trainingImageIndex, i) <- batchIndices.view.zipWithIndex) {\n",
    "        val trainingHostBuffer = trainingHostBuffers(trainingImageIndex / NumberOfTrainingSamplesPerFile)\n",
    "        val imageOffsetInFile = imageSize * (trainingImageIndex % NumberOfTrainingSamplesPerFile)\n",
    "        trainingHostBuffer.position(imageOffsetInFile)\n",
    "        trainingHostBuffer.get(imageArray)\n",
    "        labelHostBuffer.put(i, imageArray(0))\n",
    "        for (channel <- 0 until NumberOfInputChannels) {\n",
    "            for (xy <- 0 until (Width * Height)) {\n",
    "                channelArray(xy) = ((imageArray(1 + channel * Width * Height + xy) & 0xFF).toFloat + 0.5f) / 256.0f\n",
    "            }\n",
    "            inputHostBuffer.position((channel * BatchSize + i) * Width * Height)\n",
    "            inputHostBuffer.put(channelArray)\n",
    "        }\n",
    "    }\n",
    "    inputHostBuffer.position(0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fillImageHostBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def writeInputBuffer() = {\n",
    "    val event = commandQueue.enqueueWriteBuffer(inputDeviceBuffer, inputHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeInputBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeLabelBuffer() = {\n",
    "    val event = commandQueue.enqueueWriteBuffer(labelDeviceBuffer, labelHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeLabelBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val forwardKernels = fibersByOutputCellIndex.toSeq.sortBy(_._1).map {\n",
    "    case (outputCellIndex, fibers) =>\n",
    "        val forwardKernel = program.createKernel(\"forward\")\n",
    "        // TODO: clean\n",
    "        forwardKernel.setArg(0, dataDeviceBuffer)\n",
    "        forwardKernel.setArg(1, weightDeviceBuffer)\n",
    "        forwardKernel.setArg(2, biasDeviceBuffer)\n",
    "        forwardKernel.setArg(3, Address(outputCellIndex))\n",
    "        forwardKernel.setArg(4, Address(fibers.length))\n",
    "        assert(fibers.nonEmpty)\n",
    "\n",
    "        val fiberHostBuffer = MemoryUtil.memAllocShort(fibers.length * 4)\n",
    "        val fiberDeviceBuffer = try {\n",
    "            for (pair <- fibers) {\n",
    "                val (fiber, weightIndex) = pair\n",
    "                fiberHostBuffer.put(fiber.offsetX.toShort)\n",
    "                fiberHostBuffer.put(fiber.offsetY.toShort)\n",
    "                fiberHostBuffer.put(fiber.inputCellIndex.toShort)\n",
    "                fiberHostBuffer.put(weightIndex.toShort)\n",
    "            }\n",
    "            fiberHostBuffer.position(0)\n",
    "            context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "        } finally {\n",
    "            MemoryUtil.memFree(fiberHostBuffer)\n",
    "        }\n",
    "        forwardKernel.setArg(5, fiberDeviceBuffer)\n",
    "        outputCellIndex -> forwardKernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def forward() = {\n",
    "    for ((_, forwardKernel) <- forwardKernels) {\n",
    "        val event = commandQueue.enqueueNDRangeKernel(\n",
    "            forwardKernel,\n",
    "            Seq(\n",
    "                GlobalWorkSizeOnlyDimension(Address(BatchSize)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Width)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Height))\n",
    "            )\n",
    "        )\n",
    "        try {\n",
    "            event.waitForComplete.blockingAwait\n",
    "        } finally {\n",
    "            event.close()\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val scoreDataHostBuffer = MemoryUtil.memAllocFloat(scoreDataDeviceBuffer.length)\n",
    "\n",
    "def readScoreDataBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(scoreDataDeviceBuffer, scoreDataHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "readScoreDataBuffer()\n",
    "(0 until scoreDataHostBuffer.remaining by 10000).map(scoreDataHostBuffer.get).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward()\n",
    "readScoreDataBuffer()\n",
    "(0 until scoreDataHostBuffer.remaining by 10000).map(scoreDataHostBuffer.get).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forward()\n",
    "readScoreDataBuffer()\n",
    "(0 until scoreDataHostBuffer.remaining by 10000).map(scoreDataHostBuffer.get).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainLossKernel = program.createKernel(\"train_loss\")\n",
    "trainLossKernel.setArg(0, scoreDataDeviceBuffer)\n",
    "trainLossKernel.setArg(1, scoreDeltaDeviceBuffer)\n",
    "trainLossKernel.setArg(2, labelDeviceBuffer)\n",
    "trainLossKernel.setArg(3, outputLabelDeviceBuffer)\n",
    "trainLossKernel.setArg(4, lossDeviceBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLoss() = {\n",
    "    val event = commandQueue.enqueueNDRangeKernel(\n",
    "        trainLossKernel,\n",
    "        Seq(GlobalWorkSizeOnlyDimension(Address(BatchSize)))\n",
    "    )\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val lossHostBuffer = MemoryUtil.memAllocFloat(BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLossBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(lossDeviceBuffer, lossHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readLossBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val loss = {\n",
    "    val lossArray = Array.ofDim[Float](BatchSize)\n",
    "    lossHostBuffer.get(lossArray)\n",
    "    lossHostBuffer.position(0)\n",
    "    lossArray.sum / BatchSize / NumberOfClasses\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val outputLabelHostBuffer = MemoryUtil.memAlloc(BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readOutputLabelBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(outputLabelDeviceBuffer, outputLabelHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readOutputLabelBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(0 until outputLabelHostBuffer.remaining).map(outputLabelHostBuffer.get).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val lossArray = Array.ofDim[Float](BatchSize)\n",
    "    lossHostBuffer.get(lossArray)\n",
    "    lossHostBuffer.position(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "println(lossArray.toSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanLoss = {\n",
    "    val lossArray = Array.ofDim[Float](BatchSize)\n",
    "    lossHostBuffer.get(lossArray)\n",
    "    lossHostBuffer.position(0)\n",
    "    println(lossArray.toSeq)\n",
    "    lossArray.sum / BatchSize / NumberOfClasses\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(meanLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// val dataHostBuffer = MemoryUtil.memAllocFloat(dataDeviceBuffer.length)\n",
    "\n",
    "// def readDataBuffer() = {\n",
    "//     val event = commandQueue.enqueueReadBuffer(dataDeviceBuffer, dataHostBuffer)\n",
    "//     try {\n",
    "//         event.waitForComplete.blockingAwait\n",
    "//     } finally {\n",
    "//         event.close()\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// readDataBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 until dataHostBuffer.remaining by 100000).map(dataHostBuffer.get).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 until dataHostBuffer.remaining by 100000).map(dataHostBuffer.get).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// val scoreDataHostBuffer = MemoryUtil.memAllocFloat(scoreDataDeviceBuffer.length)\n",
    "\n",
    "// def readScoreDataBuffer() = {\n",
    "//     val event = commandQueue.enqueueReadBuffer(scoreDataDeviceBuffer, scoreDataHostBuffer)\n",
    "//     try {\n",
    "//         event.waitForComplete.blockingAwait\n",
    "//     } finally {\n",
    "//         event.close()\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// readScoreDataBuffer()\n",
    "\n",
    "\n",
    "\n",
    "// val dataHostBuffer = MemoryUtil.memAllocFloat(dataDeviceBuffer.length)\n",
    "\n",
    "// def readDataBuffer() = {\n",
    "//     val event = commandQueue.enqueueReadBuffer(dataDeviceBuffer, dataHostBuffer)\n",
    "//     try {\n",
    "//         event.waitForComplete.blockingAwait\n",
    "//     } finally {\n",
    "//         event.close()\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// readDataBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//     kernel void backward(global float* delta,\n",
    "//                          global float* weight,\n",
    "//                          const size_t input_cell_index,\n",
    "//                          const size_t number_of_fibers,\n",
    "//                          constant struct backward_fiber* backward_fibers) {\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// TODO: wipe out input delta\n",
    "val backwardKernels = fibersByInputCellIndex.toSeq.sortBy(_._1).map {\n",
    "    case (inputCellIndex, fibers) =>\n",
    "        val backwardKernel = program.createKernel(\"backward\")\n",
    "        // TODO: clean\n",
    "        backwardKernel.setArg(0, deltaDeviceBuffer)\n",
    "        backwardKernel.setArg(1, weightDeviceBuffer)\n",
    "        backwardKernel.setArg(2, Address(inputCellIndex))\n",
    "        backwardKernel.setArg(3, Address(fibers.length))\n",
    "        assert(fibers.nonEmpty)\n",
    "\n",
    "        val fiberHostBuffer = MemoryUtil.memAllocShort(fibers.length * 4)\n",
    "        val fiberDeviceBuffer = try {\n",
    "            for (pair <- fibers) {\n",
    "                val (fiber, weightIndex) = pair\n",
    "                fiberHostBuffer.put((-fiber.offsetX).toShort)\n",
    "                fiberHostBuffer.put((-fiber.offsetY).toShort)\n",
    "                fiberHostBuffer.put(fiber.outputCellIndex.toShort)\n",
    "                fiberHostBuffer.put(weightIndex.toShort)\n",
    "            }\n",
    "            fiberHostBuffer.position(0)\n",
    "            context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "        } finally {\n",
    "            MemoryUtil.memFree(fiberHostBuffer)\n",
    "        }\n",
    "        backwardKernel.setArg(4, fiberDeviceBuffer)\n",
    "        inputCellIndex -> backwardKernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def backward() = {\n",
    "    for ((_, backwardKernel) <- backwardKernels.reverseIterator) {\n",
    "        val event = commandQueue.enqueueNDRangeKernel(\n",
    "            backwardKernel,\n",
    "            Seq(\n",
    "                GlobalWorkSizeOnlyDimension(Address(BatchSize)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Width)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Height))\n",
    "            )\n",
    "        )\n",
    "        try {\n",
    "            event.waitForComplete.blockingAwait\n",
    "        } finally {\n",
    "            event.close()\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// kernel void update_bias(global float* delta, global float* bias) {\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val updateBiasKernel = program.createKernel(\"update_bias\")\n",
    "updateBiasKernel.setArg(0, deltaDeviceBuffer)\n",
    "updateBiasKernel.setArg(1, biasDeviceBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBias() = {\n",
    "    val event = commandQueue.enqueueNDRangeKernel(\n",
    "        updateBiasKernel,\n",
    "        Seq(GlobalWorkSizeOnlyDimension(Address(NumberOfCells)))\n",
    "    )\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updateBias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//         kernel void update_weight(global float* data, global float* delta, global float* weight, global short4* fibers) {\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val updateWeightKernel = {\n",
    "    val kernel = program.createKernel(\"update_weight\")\n",
    "    kernel.setArg(0, dataDeviceBuffer)\n",
    "    kernel.setArg(1, deltaDeviceBuffer)\n",
    "    kernel.setArg(2, weightDeviceBuffer)\n",
    "    \n",
    "    val fiberHostBuffer = MemoryUtil.memAllocShort(fibers.length * 4)\n",
    "\n",
    "    try {\n",
    "        for (fiber <- fibers) {\n",
    "            fiberHostBuffer.put(fiber.offsetX.toShort)\n",
    "            fiberHostBuffer.put(fiber.offsetY.toShort)\n",
    "            fiberHostBuffer.put(fiber.inputCellIndex.toShort)\n",
    "            fiberHostBuffer.put(fiber.outputCellIndex.toShort)\n",
    "        }\n",
    "        fiberHostBuffer.position(0)\n",
    "        val fiberDeviceBuffer = context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "        try {\n",
    "            kernel.setArg(3, fiberDeviceBuffer)\n",
    "            kernel\n",
    "        } finally {\n",
    "            //fiberDeviceBuffer.close()\n",
    "        }\n",
    "    } finally {\n",
    "        MemoryUtil.memFree(fiberHostBuffer)\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWeight() = {\n",
    "    val event = commandQueue.enqueueNDRangeKernel(\n",
    "        updateWeightKernel,\n",
    "        Seq(GlobalWorkSizeOnlyDimension(Address(fibers.length)))\n",
    "    )\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updateWeight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val deltaHostBuffer = MemoryUtil.memAllocFloat(deltaDeviceBuffer.length)\n",
    "\n",
    "def readDeltaBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(deltaDeviceBuffer, deltaHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}\n",
    "\n",
    "readDeltaBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deltaHostBuffer.get(531140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i <- 0 until 1000) {\n",
    "    forward()\n",
    "    trainLoss()\n",
    "    readLossBuffer()\n",
    "    println(meanLoss)\n",
    "    backward()\n",
    "    updateBias()\n",
    "    updateWeight()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12.2",
   "language": "scala",
   "name": "scala-2.12.2"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala212",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
