{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                       \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                       \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                          \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.lwjgl:lwjgl:3.1.2`\n",
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "import $ivy.`com.thoughtworks.compute::opencl:0.1.0`\n",
    "import $ivy.`com.dongxiguo::fastring:0.3.1`\n",
    "import $ivy.`com.thoughtworks.raii::asynchronoussemaphore:2.1.0-RC0`\n",
    "import $ivy.`eu.timepit::refined:0.8.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mammonite.ops._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.channels._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.StandardOpenOption\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ammonite.ops._\n",
    "import java.io._\n",
    "import java.nio.channels._\n",
    "import java.nio.file.StandardOpenOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mLwjglRuntimeUrl\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnet\u001b[39m.\u001b[32mURL\u001b[39m = https://repo1.maven.org/maven2/org/lwjgl/lwjgl/3.1.2/lwjgl-3.1.2-natives-linux.jar"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val LwjglRuntimeUrl = {\n",
    "    import java.net._\n",
    "    val lwjglClassifier = if (util.Properties.isMac) {\n",
    "        \"natives-macos\"\n",
    "    } else if (util.Properties.osName.startsWith(\"Linux\")) {\n",
    "        \"natives-linux\"\n",
    "    } else if (util.Properties.isWin) {\n",
    "        \"natives-windows\"\n",
    "    } else {\n",
    "        throw new Exception(s\"lwjgl does not support ${util.Properties.osName}\")\n",
    "    }\n",
    "    new URL(s\"https://repo1.maven.org/maven2/org/lwjgl/lwjgl/3.1.2/lwjgl-3.1.2-$lwjglClassifier.jar\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Workaround for https://github.com/jupyter-scala/jupyter-scala/issues/128\n",
    "interp.load.cp {\n",
    "    val temporaryJar = tmp()\n",
    "    val httpStream = LwjglRuntimeUrl.openStream()\n",
    "    try {\n",
    "        val httpChannel = Channels.newChannel(httpStream)\n",
    "        try {\n",
    "            val fileChannel = FileChannel.open(temporaryJar.toNIO, StandardOpenOption.WRITE)\n",
    "            try {\n",
    "                fileChannel.transferFrom(httpChannel, 0, Long.MaxValue)\n",
    "            } finally {\n",
    "                fileChannel.close()\n",
    "            }\n",
    "        } finally {\n",
    "            httpChannel.close()\n",
    "        }\n",
    "    } finally {\n",
    "        httpStream.close()\n",
    "    }\n",
    "    temporaryJar\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// import $ivy.`com.thoughtworks.compute::opencl:0.1.0`\n",
    "// import $ivy.`com.thoughtworks.raii::asynchronoussemaphore:2.1.0-RC0`\n",
    "\n",
    "// interp.load.cp(Seq(\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/AsynchronousSemaphore/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/asynchronous/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/shared/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"RAII.scala/covariant/.jvm/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/OpenCLCodeGenerator/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/Memory/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/OpenCL/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.pwd/ammonite.ops.RelPath(\"Compute.scala/Closeables/target/scala-2.12/classes\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scalaz/scalaz-core_2.12/bundles/scalaz-core_2.12-7.2.14.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.continuation/continuation_2.12/jars/continuation_2.12-1.1.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.chuusai/shapeless_2.12/bundles/shapeless_2.12-2.3.2.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.typelevel/macro-compat_2.12/jars/macro-compat_2.12-1.1.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.tryt/covariant_2.12/jars/covariant_2.12-2.0.3.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.future/future_2.12/jars/future_2.12-1.1.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(s\".ivy2/cache/org.lwjgl/lwjgl/jars/lwjgl-3.1.2-${lwjglClassifier}.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.dongxiguo/fastring_2.12/jars/fastring_2.12-0.3.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scala-lang/scala-reflect/jars/scala-reflect-2.12.3.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.lwjgl/lwjgl-opencl/jars/lwjgl-opencl-3.1.2.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/eu.timepit/refined_2.12/jars/refined_2.12-0.8.2.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scala-lang/scala-compiler/jars/scala-compiler-2.12.3.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scala-lang.modules/scala-xml_2.12/bundles/scala-xml_2.12-1.0.6.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.each/each_2.12/jars/each_2.12-3.3.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.sde/core_2.12/jars/core_2.12-3.3.1.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/org.scalaz/scalaz-effect_2.12/bundles/scalaz-effect_2.12-7.2.7.jar\"),\n",
    "// ammonite.ops.Path.home/ammonite.ops.RelPath(\".ivy2/cache/com.thoughtworks.sde/comprehension-monad_2.12/jars/comprehension-monad_2.12-3.3.1.jar\")\n",
    "// ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.continuation._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.dongxiguo.fastring.Fastring.Implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.dongxiguo.fastring.Fastring\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36meu.timepit.refined.api.Refined\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36meu.timepit.refined.numeric.{Negative, Positive}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.lwjgl.opencl._, CL10._, CL12._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.lwjgl.system.MemoryUtil\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.compute.Memory.Address\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.compute.OpenCL.CommandQueue.GlobalWorkSizeOnlyDimension\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.compute.OpenCL\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.thoughtworks.continuation._\n",
    "import com.thoughtworks.future._\n",
    "\n",
    "import com.dongxiguo.fastring.Fastring.Implicits._\n",
    "import com.dongxiguo.fastring.Fastring\n",
    "import eu.timepit.refined.api.Refined\n",
    "import eu.timepit.refined.numeric.{Negative, Positive}\n",
    "\n",
    "import org.lwjgl.opencl._, CL10._, CL12._\n",
    "import org.lwjgl.system.MemoryUtil\n",
    "\n",
    "import com.thoughtworks.compute.Memory.Address\n",
    "import com.thoughtworks.compute.OpenCL.CommandQueue.GlobalWorkSizeOnlyDimension\n",
    "import com.thoughtworks.compute.OpenCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCL environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mplatform\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mPlatform\u001b[39m = \u001b[33mPlatform\u001b[39m(\u001b[32m139689515197560L\u001b[39m, org.lwjgl.opencl.CLCapabilities@7f57607a)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val platform = OpenCL.platforms.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdevice\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mDevice\u001b[39m = \u001b[33mDevice\u001b[39m(\u001b[32m139690054020288L\u001b[39m, org.lwjgl.opencl.CLCapabilities@4ec504b7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val device = platform.devices.maxBy { device =>\n",
    "  Seq(CL_DEVICE_TYPE_CPU, CL_DEVICE_TYPE_GPU, CL_DEVICE_TYPE_ACCELERATOR).indexOf(device.deviceType)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcontext\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mContext\u001b[39m = com.thoughtworks.compute.OpenCL$Context@45c01749"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val context = platform.createContext({ (errorInfo, data) =>\n",
    "  publish.stderr(errorInfo)\n",
    "}, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcommandQueue\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mCommandQueue\u001b[39m = com.thoughtworks.compute.OpenCL$CommandQueue@2109bf94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val commandQueue = context.createCommandQueue(\n",
    "    device,\n",
    "    Map(\n",
    "        CL_QUEUE_PROPERTIES -> (CL_QUEUE_OUT_OF_ORDER_EXEC_MODE_ENABLE & device.queueProperties)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mFiber\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/**\n",
    "  * @note [[outputCellIndex]] must be greater than [[inputCellIndex]] for now. The limitation will be removed in future version\n",
    "  */\n",
    "final case class Fiber(offsetX: Int, offsetY: Int, inputCellIndex: Int, outputCellIndex: Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfInputChannels\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3\u001b[39m\n",
       "\u001b[36mNumberOfHiddenCells\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m100\u001b[39m\n",
       "\u001b[36mNumberOfClasses\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m\n",
       "\u001b[36mNumberOfCells\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m113\u001b[39m\n",
       "\u001b[36mWidth\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m\n",
       "\u001b[36mHeight\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m\n",
       "\u001b[36mBatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m\n",
       "\u001b[36mNumberOfVotesRequiredForLabelClass\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m300\u001b[39m\n",
       "\u001b[36mLearningRate\u001b[39m: \u001b[32mFloat\u001b[39m = \u001b[32m0.001F\u001b[39m\n",
       "\u001b[36mBiasLearningRate\u001b[39m: \u001b[32mFloat\u001b[39m = \u001b[32m0.0F\u001b[39m\n",
       "\u001b[36mL2Regularization\u001b[39m: \u001b[32mFloat\u001b[39m = \u001b[32m0.0F\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfInputChannels = 3\n",
    "\n",
    "val NumberOfHiddenCells = 100\n",
    "\n",
    "val NumberOfClasses = 10\n",
    "\n",
    "val NumberOfCells = NumberOfInputChannels + NumberOfHiddenCells + NumberOfClasses // Must larger than NumberOfInputChannels + NumberOfClasses\n",
    "\n",
    "val Width = 32\n",
    "\n",
    "val Height = 32\n",
    "\n",
    "val BatchSize = 32\n",
    "\n",
    "val NumberOfVotesRequiredForLabelClass = 300;\n",
    "\n",
    "val LearningRate = 0.001f\n",
    "val BiasLearningRate = 0.0f//0003f\n",
    "\n",
    "val L2Regularization = 0.0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minputFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mFiber\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputFibers = for {\n",
    "    outputCellIndex <- 3 until NumberOfCells\n",
    "    inputCellIndex <- 0 until NumberOfInputChannels\n",
    "    offsetX <- -3 to 3\n",
    "    offsetY <- -3 to 3\n",
    "    if math.random < math.pow(offsetX * offsetX + offsetY * offsetY + 1, -1.3) * math.max(0.003, 1.0 - (outputCellIndex - 3) / 0.2 / NumberOfCells)\n",
    "} yield Fiber(offsetX, offsetY, inputCellIndex, outputCellIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msparseFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mFiber\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m5\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m6\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-4\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m7\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m8\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparseFibers = for {\n",
    "    outputCellIndex <- 3 until NumberOfCells\n",
    "    inputCellIndex <- Iterator.iterate(outputCellIndex.toDouble)(_ * math.random * 0.7)\n",
    "                         .takeWhile(_ > 0.5)\n",
    "                         .map { i => outputCellIndex - math.ceil(i).toInt }\n",
    "} yield Fiber((util.Random.nextGaussian * 2).toInt, (util.Random.nextGaussian * 3).toInt, inputCellIndex, outputCellIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moffsetFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mSeqView\u001b[39m[\u001b[32mFiber\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32m_\u001b[39m]] = \u001b[33mSeqView\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val offsetFibers = (inputFibers.view ++ sparseFibers).map { fiber =>\n",
    "    def randomOffset() = {\n",
    "      (util.Random.nextGaussian() * 3).toInt\n",
    "    }\n",
    "    @scala.annotation.tailrec\n",
    "    def retry: Fiber = {\n",
    "        val randomOffsetX = (util.Random.nextGaussian() * 2).toInt\n",
    "        val randomOffsetY = (util.Random.nextGaussian() * 2).toInt\n",
    "        if (randomOffsetX == 0 && randomOffsetY == 0) {\n",
    "            retry\n",
    "        } else {\n",
    "            Fiber(fiber.offsetX + randomOffsetX, fiber.offsetY + randomOffsetY, fiber.inputCellIndex, fiber.outputCellIndex)\n",
    "        }\n",
    "    }\n",
    "    retry\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ArraySeq\n",
       "\u001b[39m\n",
       "\u001b[36mallFibers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mmutable\u001b[39m.\u001b[32mArraySeq\u001b[39m[\u001b[32mFiber\u001b[39m] = \u001b[33mArraySeq\u001b[39m(\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-2\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m-4\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  \u001b[33mFiber\u001b[39m(\u001b[32m5\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.ArraySeq\n",
    "val allFibers = (offsetFibers ++ inputFibers ++ sparseFibers).distinct.to[ArraySeq]\n",
    "// val allFibers = (3 until 13).map(Fiber(-1, -1, 0, _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfibersByOutputCellIndex\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mInt\u001b[39m, \u001b[32mSeq\u001b[39m[(\u001b[32mFiber\u001b[39m, \u001b[32mInt\u001b[39m)]] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m69\u001b[39m -> \u001b[33mSeqView\u001b[39m(\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m445\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-4\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m38\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m446\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m59\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m447\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m67\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m448\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m68\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m449\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m1085\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-4\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m38\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m1086\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m59\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m1087\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m67\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m1088\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m68\u001b[39m, \u001b[32m69\u001b[39m), \u001b[32m1089\u001b[39m)\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fibersByOutputCellIndex = allFibers.view.zipWithIndex.groupBy(_._1.outputCellIndex).withDefaultValue(Nil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mfibersByInputCellIndex\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mInt\u001b[39m, \u001b[32mSeq\u001b[39m[(\u001b[32mFiber\u001b[39m, \u001b[32mInt\u001b[39m)]] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m69\u001b[39m -> \u001b[33mSeqView\u001b[39m(\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-5\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m80\u001b[39m), \u001b[32m497\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m84\u001b[39m), \u001b[32m515\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m89\u001b[39m), \u001b[32m540\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m100\u001b[39m), \u001b[32m600\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-5\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m80\u001b[39m), \u001b[32m1137\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-3\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m84\u001b[39m), \u001b[32m1155\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m-1\u001b[39m, \u001b[32m-3\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m89\u001b[39m), \u001b[32m1180\u001b[39m),\n",
       "    (\u001b[33mFiber\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m-1\u001b[39m, \u001b[32m69\u001b[39m, \u001b[32m100\u001b[39m), \u001b[32m1240\u001b[39m)\n",
       "  ),\n",
       "  \u001b[32m101\u001b[39m -> \u001b[33mSeqView\u001b[39m(\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fibersByInputCellIndex = allFibers.view.zipWithIndex.groupBy(_._1.inputCellIndex).withDefaultValue(Nil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating OpenCL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mforwardCode\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forwardCode = fastraw\"\"\"\n",
    "    struct forward_fiber {\n",
    "        short offset_x;\n",
    "        short offset_y;\n",
    "        unsigned short input_cell_index;\n",
    "        unsigned short weight_index;\n",
    "    };\n",
    "    float convolution(size_t image_index,\n",
    "                      size_t output_x,\n",
    "                      size_t output_y,\n",
    "                      global float* data,\n",
    "                      global float* weight,\n",
    "                      const size_t number_of_fibers,\n",
    "                      constant struct forward_fiber* forward_fibers);\n",
    "    float convolution(size_t image_index,\n",
    "                      size_t output_x,\n",
    "                      size_t output_y,\n",
    "                      global float* data,\n",
    "                      global float* weight,\n",
    "                      const size_t number_of_fibers,\n",
    "                      constant struct forward_fiber* forward_fibers) {\n",
    "        float output_data = 0.0f;\n",
    "        for (size_t i = 0; i < number_of_fibers; i++) {\n",
    "            struct forward_fiber fiber = forward_fibers[i];\n",
    "            ptrdiff_t offset_x = fiber.offset_x;\n",
    "            ptrdiff_t offset_y = fiber.offset_y;\n",
    "            ptrdiff_t input_x = output_x + offset_x;\n",
    "            ptrdiff_t input_y = output_y + offset_y;\n",
    "            if (\n",
    "                input_x >= 0 &&\n",
    "                input_x < $Width &&\n",
    "                input_y >= 0 &&\n",
    "                input_y < $Height\n",
    "            ) {\n",
    "                size_t input_cell_index = fiber.input_cell_index;\n",
    "                size_t weight_index = fiber.weight_index;\n",
    "                float input_data = data[\n",
    "                    input_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    input_y * $Width +\n",
    "                    input_x\n",
    "                ];\n",
    "                output_data += weight[weight_index] * input_data;\n",
    "            }\n",
    "        }\n",
    "        return output_data;\n",
    "    }\n",
    "    kernel void forward(global float* data,\n",
    "                        global float* weight,\n",
    "                        global float* bias,\n",
    "                        const size_t output_cell_index,\n",
    "                        const size_t number_of_fibers,\n",
    "                        constant struct forward_fiber* forward_fibers) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        size_t output_x = get_global_id(1);\n",
    "        size_t output_y = get_global_id(2);\n",
    "        data[\n",
    "            output_cell_index * ${Width * Height * BatchSize} +\n",
    "            image_index * ${Width * Height} +\n",
    "            output_y * $Width +\n",
    "            output_x\n",
    "        ] = fmax(0.0f, convolution(image_index, output_x, output_y, data, weight, number_of_fibers, forward_fibers) + bias[output_cell_index]);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`backward_fiber` is a fiber from input's view. It's `offset_x` and `offset_y` is always the negative value of the corresonding `forward_fiber`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mbackwardCode\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backwardCode = fastraw\"\"\"\n",
    "    struct backward_fiber {\n",
    "        short offset_x;\n",
    "        short offset_y;\n",
    "        unsigned short output_cell_index;\n",
    "        unsigned short weight_index;\n",
    "    };\n",
    "\n",
    "    kernel void backward(global float* delta,\n",
    "                         global float* weight,\n",
    "                         const size_t input_cell_index,\n",
    "                         const size_t number_of_fibers,\n",
    "                         constant struct backward_fiber* backward_fibers) {\n",
    "        const size_t image_index = get_global_id(0);\n",
    "        const size_t input_x = get_global_id(1);\n",
    "        const size_t input_y = get_global_id(2);\n",
    "        float input_delta = 0.0f;\n",
    "        for (size_t i = 0; i < number_of_fibers; i++) {\n",
    "            const struct backward_fiber fiber = backward_fibers[i];\n",
    "            const ptrdiff_t offset_x = fiber.offset_x;\n",
    "            const ptrdiff_t offset_y = fiber.offset_y;\n",
    "            const ptrdiff_t output_x = input_x + offset_x;\n",
    "            const ptrdiff_t output_y = input_y + offset_y;\n",
    "            if (\n",
    "                output_x >= 0 &&\n",
    "                output_x < $Width &&\n",
    "                output_y >= 0 &&\n",
    "                output_y < $Height\n",
    "            ) {\n",
    "                size_t output_cell_index = fiber.output_cell_index;\n",
    "                size_t weight_index = fiber.weight_index;\n",
    "                float output_delta = delta[\n",
    "                    output_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    output_y * $Width +\n",
    "                    output_x\n",
    "                ];\n",
    "                input_delta += weight[weight_index] * output_delta;\n",
    "            }\n",
    "        }\n",
    "        delta[\n",
    "            input_cell_index * ${Width * Height * BatchSize} +\n",
    "            image_index * ${Width * Height} +\n",
    "            input_y * $Width + input_x\n",
    "        ] = input_delta;\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupdateBiasCode\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def updateBiasCode = fastraw\"\"\"\n",
    "    kernel void update_bias(global float* delta, global float* bias) {\n",
    "        size_t cell_index = get_global_id(0);\n",
    "        float accumulator = 0.0;\n",
    "        for (size_t i = 0; i < ${BatchSize * Width * Height}; i++) {\n",
    "            accumulator += delta[cell_index * ${BatchSize * Width * Height} + i];\n",
    "        }\n",
    "        float old_bias = bias[cell_index];\n",
    "        float new_bias = old_bias - (accumulator + old_bias * ${L2Regularization}f) * ${BiasLearningRate}f;\n",
    "        bias[cell_index] = new_bias;\n",
    "//         write_mem_fence(CLK_GLOBAL_MEM_FENCE);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupdateWeightCode\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def updateWeightCode = fastraw\"\"\"\n",
    "    struct plain_fiber {\n",
    "        short offset_x;\n",
    "        short offset_y;\n",
    "        unsigned short input_cell_index;\n",
    "        unsigned short output_cell_index;\n",
    "    };\n",
    "    kernel void update_weight(global float* data, global float* delta, global float* weight, global struct plain_fiber* fibers) {\n",
    "        size_t i = get_global_id(0);\n",
    "        struct plain_fiber fiber = fibers[i];\n",
    "        ptrdiff_t offset_x = fiber.offset_x;\n",
    "        ptrdiff_t offset_y = fiber.offset_y;\n",
    "        size_t input_cell_index = fiber.input_cell_index;\n",
    "        size_t output_cell_index = fiber.output_cell_index;\n",
    "        size_t input_cell_start = input_cell_index * ${Width * Height * BatchSize};\n",
    "        size_t output_cell_start = output_cell_index * ${Width * Height * BatchSize};\n",
    "        float delta_weight = 0.0f;\n",
    "        for (size_t image_index = 0; image_index < $BatchSize; image_index++) {\n",
    "            size_t input_image_start = input_cell_start + image_index * ${Width * Height};\n",
    "            size_t output_image_start = output_cell_start + image_index * ${Width * Height};\n",
    "            for (ptrdiff_t input_y = 0; input_y < $Width; input_y++) {\n",
    "                ptrdiff_t output_y = input_y - offset_y;\n",
    "                if (output_y >= 0 && output_y < $Height) {\n",
    "                    size_t input_row_start = input_image_start + input_y * $Width;\n",
    "                    size_t output_row_start = output_image_start + output_y * $Width;\n",
    "                    for (ptrdiff_t input_x = 0; input_x < $Width; input_x++) {\n",
    "                        ptrdiff_t output_x = input_x - offset_x;\n",
    "                        if (output_x >= 0 && output_x < $Width) {\n",
    "                            delta_weight += data[input_row_start + input_x] *\n",
    "                                            delta[output_row_start + output_x];\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "\n",
    "        }\n",
    "        float old_weight = weight[i];\n",
    "        float new_weight = old_weight - (delta_weight + old_weight * ${L2Regularization}f) * ${LearningRate}f;\n",
    "        weight[i] = new_weight;\n",
    "//         write_mem_fence(CLK_GLOBAL_MEM_FENCE);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainLossCode\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainLossCode = {\n",
    "    def incorrectClasses = {\n",
    "        {\n",
    "            for (classIndex <- 0 until NumberOfClasses) yield fastraw\"\"\"\n",
    "                size_t image_start_$classIndex = ${classIndex * BatchSize * Width * Height} + image_index * ${Width * Height};\n",
    "                unsigned short class_votes_$classIndex = 0;\n",
    "                for (size_t xy = 0; xy < ${Width * Height}; xy++) {\n",
    "                    float pixel_score = score_data[image_start_$classIndex + xy];\n",
    "                    if (pixel_score > 0.0f) {\n",
    "                        class_votes_$classIndex += 1;\n",
    "                    }\n",
    "                    if ($classIndex != label) {\n",
    "                        image_total_loss += pixel_score * pixel_score;\n",
    "                        score_delta[image_start_$classIndex + xy] = pixel_score * ${2.0f / (Width * Height * BatchSize)}f;\n",
    "                    }\n",
    "                }\n",
    "                if (class_votes_$classIndex >= image_max_votes) {\n",
    "                    image_max_votes = class_votes_$classIndex;\n",
    "                    output_label = $classIndex;\n",
    "                }\n",
    "            \"\"\"\n",
    "        }.mkFastring(\"\\n\")\n",
    "    }\n",
    "    def correctClass = {\n",
    "        fastraw\"\"\"\n",
    "            size_t correct_image_start = label * ${BatchSize * Width * Height} + image_index * ${Width * Height};\n",
    "            unsigned short number_of_votes = 0;\n",
    "            for (size_t xy = 0; xy < ${Width * Height}; xy++) {\n",
    "                if (score_data[correct_image_start + xy] >= 1.0f) {\n",
    "                    number_of_votes += 1;\n",
    "                }\n",
    "            }\n",
    "            for (size_t xy = 0; xy < ${Width * Height}; xy++) {\n",
    "                if (number_of_votes < $NumberOfVotesRequiredForLabelClass) {\n",
    "                    float pixel_score = score_data[correct_image_start + xy];\n",
    "                    float margin = 1.0f - pixel_score;\n",
    "                    score_delta[correct_image_start + xy] = margin * ${-(NumberOfClasses - 1).toFloat / (Width * Height * BatchSize)}f;\n",
    "                    image_total_loss += ${(NumberOfClasses - 1) * 0.5}f * margin * margin;\n",
    "                } else {\n",
    "                    score_delta[correct_image_start + xy] = 0.0f;\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "    }\n",
    "    fastraw\"\"\"\n",
    "        kernel void train_loss(global float* score_data,\n",
    "                               global float* score_delta,\n",
    "                               constant unsigned char* labels,\n",
    "                               global unsigned char* output_labels,\n",
    "                               global float* loss) {\n",
    "            size_t image_index = get_global_id(0);\n",
    "            size_t label = labels[image_index];\n",
    "            float image_total_loss = 0.0f;\n",
    "            unsigned short image_max_votes = 0;\n",
    "            unsigned char output_label = 0;\n",
    "            $correctClass\n",
    "            $incorrectClasses\n",
    "            loss[image_index] = image_total_loss / ${(Width * Height).toFloat}f;\n",
    "            output_labels[image_index] = output_label;\n",
    "//             write_mem_fence(CLK_GLOBAL_MEM_FENCE);\n",
    "        }\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mweightInitializationCode\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weightInitializationCode = raw\"\"\"\n",
    "    kernel void forward_sum(global float* data,\n",
    "                            global float* weight,\n",
    "                            const size_t output_cell_index,\n",
    "                            const size_t number_of_fibers,\n",
    "                            constant struct forward_fiber* forward_fibers,\n",
    "                            global float* sum_of_image) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        float sum = 0.0f;\n",
    "        for (ptrdiff_t output_y = 0; output_y < $Height; output_y++) {\n",
    "            for (ptrdiff_t output_x = 0; output_x < $Width; output_x++) {\n",
    "                float raw_output = convolution(image_index, output_x, output_y, data, weight, number_of_fibers, forward_fibers);\n",
    "                data[\n",
    "                    output_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    output_y * $Width + output_x\n",
    "                ] = raw_output;\n",
    "                sum += raw_output;\n",
    "            }\n",
    "        }\n",
    "        sum_of_image[image_index] = sum;\n",
    "    }\n",
    "    \n",
    "    kernel void square_sum(global float* data,\n",
    "                           const float mean,\n",
    "                           const size_t output_cell_index,\n",
    "                           global float* square_sum_of_image) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        float sum = 0.0f;\n",
    "        for (ptrdiff_t output_y = 0; output_y < $Height; output_y++) {\n",
    "            for (ptrdiff_t output_x = 0; output_x < $Width; output_x++) {\n",
    "                float biased_output = data[\n",
    "                    output_cell_index * ${Width * Height * BatchSize} +\n",
    "                    image_index * ${Width * Height} +\n",
    "                    output_y * $Width +\n",
    "                    output_x\n",
    "                ] - mean;\n",
    "                sum += biased_output * biased_output;\n",
    "            }\n",
    "        }\n",
    "        square_sum_of_image[image_index] = sum;\n",
    "    }\n",
    "    \n",
    "    kernel void adjust_weight(global float* weight,\n",
    "                              global float* variance,\n",
    "                              global struct plain_fiber* fibers) {\n",
    "        size_t fiber_index = get_global_id(0);\n",
    "        struct plain_fiber fiber = fibers[fiber_index];\n",
    "        weight[fiber_index] = weight[fiber_index] / variance[fiber.output_cell_index];\n",
    "    }\n",
    "    \n",
    "    kernel void adjust_data(global float* data,\n",
    "                            const size_t output_cell_index,\n",
    "                            const float variance,\n",
    "                            const float mean) {\n",
    "        size_t image_index = get_global_id(0);\n",
    "        size_t output_x = get_global_id(1);\n",
    "        size_t output_y = get_global_id(2);\n",
    "        size_t i = output_cell_index * ${Width * Height * BatchSize} +\n",
    "                   image_index * ${Width * Height} +\n",
    "                   output_y * $Width +\n",
    "                   output_x;\n",
    "        data[i] = fmax(0.0f, (data[i] - mean) / variance);\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcode\u001b[39m: \u001b[32mFastring\u001b[39m = \u001b[33mcmd23Wrapper.Helper\u001b[39m(\n",
       "  \u001b[32m\"\"\"\n",
       "  \n",
       "    \n",
       "  \"\"\"\u001b[39m,\n",
       "  \u001b[32m\"\"\"\n",
       "  \n",
       "    struct forward_fiber {  \n",
       "        short offset_x;  \n",
       "        short offset_y;  \n",
       "        unsigned short input_cell_index;  \n",
       "        unsigned short weight_index;  \n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mprogram\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mProgram\u001b[39m = com.thoughtworks.compute.OpenCL$Program@9c4ba84"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val code = fastraw\"\"\"\n",
    "    $forwardCode\n",
    "    $backwardCode\n",
    "    $updateWeightCode\n",
    "    $updateBiasCode\n",
    "    $trainLossCode\n",
    "    $weightInitializationCode\n",
    "\"\"\"\n",
    "val program = context.createProgramWithSource(code)\n",
    "program.build().blockingAwait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.net.URL\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.File\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.rauschig.jarchivelib.{Archiver, ArchiverFactory}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.channels._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file._\u001b[39m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.net.URL\n",
    "import java.io.File\n",
    "import $ivy.`org.rauschig:jarchivelib:0.7.1`\n",
    "import org.rauschig.jarchivelib.{Archiver, ArchiverFactory}\n",
    "import java.nio.channels._\n",
    "import java.nio.file._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mCifar10Url\u001b[39m: \u001b[32mURL\u001b[39m = http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\n",
       "\u001b[36mCifarDirectory\u001b[39m: \u001b[32mFile\u001b[39m = cifar-10-batches-bin"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Cifar10Url = new URL(\"http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\")\n",
    "val CifarDirectory = new File(\"cifar-10-batches-bin\")\n",
    "if (!CifarDirectory.exists) {\n",
    "    import sys.process._\n",
    "    val targzFile = File.createTempFile(\"cifar-10-binary\", \".tar.gz\")\n",
    "    val cifarHttpStream = Cifar10Url.openStream()\n",
    "    try {\n",
    "        val httpChannel = Channels.newChannel(cifarHttpStream)\n",
    "        try {\n",
    "            val fileChannel = FileChannel.open(targzFile.toPath, StandardOpenOption.WRITE)\n",
    "            try {\n",
    "                fileChannel.transferFrom(httpChannel, 0, Long.MaxValue)\n",
    "            } finally {\n",
    "                fileChannel.close()\n",
    "            }\n",
    "        } finally {\n",
    "            httpChannel.close()\n",
    "        }\n",
    "    } finally {\n",
    "        cifarHttpStream.close()\n",
    "    }\n",
    "    val archiver: Archiver = ArchiverFactory.createArchiver(\"tar\", \"gz\")\n",
    "    archiver.extract(targzFile, new File(sys.props(\"user.dir\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfTrainingSamplesPerFile\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10000\u001b[39m\n",
       "\u001b[36mNumberOfTrainingFiles\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m5\u001b[39m\n",
       "\u001b[36mNumberOfTrainingSamples\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m50000\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.channels.FileChannel\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.Paths\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.Path\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.StandardOpenOption\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mtrainingHostBuffers\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mMappedByteBuffer\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=30730000 cap=30730000],\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=30730000 cap=30730000],\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=30730000 cap=30730000],\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=30730000 cap=30730000],\n",
       "  java.nio.DirectByteBufferR[pos=0 lim=30730000 cap=30730000]\n",
       ")\n",
       "\u001b[36mtestHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mMappedByteBuffer\u001b[39m = java.nio.DirectByteBufferR[pos=0 lim=30730000 cap=30730000]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfTrainingSamplesPerFile = 10000\n",
    "val NumberOfTrainingFiles = 5\n",
    "val NumberOfTrainingSamples = NumberOfTrainingFiles * NumberOfTrainingSamplesPerFile\n",
    "\n",
    "import java.nio.channels.FileChannel\n",
    "import java.nio.file.Paths\n",
    "import java.nio.file.Path\n",
    "import java.nio.file.StandardOpenOption\n",
    "\n",
    "val trainingHostBuffers = for (i <- 1 to NumberOfTrainingFiles) yield {\n",
    "    val batchPath = CifarDirectory.toPath.resolve(s\"data_batch_$i.bin\")\n",
    "    val channel = FileChannel.open(batchPath, StandardOpenOption.READ)\n",
    "    try {\n",
    "        channel.map(FileChannel.MapMode.READ_ONLY, 0L, channel.size)\n",
    "    } finally {\n",
    "        channel.close()\n",
    "    }\n",
    "}\n",
    "\n",
    "val testHostBuffer = {\n",
    "    val batchPath = CifarDirectory.toPath.resolve(s\"test_batch.bin\")\n",
    "    val channel = FileChannel.open(batchPath, StandardOpenOption.READ)\n",
    "    try {\n",
    "        channel.map(FileChannel.MapMode.READ_ONLY, 0L, channel.size)\n",
    "    } finally {\n",
    "        channel.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@6f064dc7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize * Width * Height * NumberOfCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdeltaDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@6638b390"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val deltaDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize * Width * Height * NumberOfCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbiasDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@3c4f61b5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val biasDeviceBuffer = context.createUninitializedBuffer[Float](NumberOfCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mweightDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@62e842d7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val weightDeviceBuffer = context.createUninitializedBuffer[Float](allFibers.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mweightHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mFloatBuffer\u001b[39m = java.nio.DirectFloatBufferU[pos=0 lim=1300 cap=1300]\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteWeightBuffer\u001b[39m"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val weightHostBuffer = MemoryUtil.memAllocFloat(allFibers.length)\n",
    "def writeWeightBuffer() = {\n",
    "    for ((outputCellIndex, fibers) <- fibersByOutputCellIndex) {\n",
    "        for ((fiber, fiberIndex) <- fibers) {\n",
    "            weightHostBuffer.put(fiberIndex, util.Random.nextGaussian.toFloat)\n",
    "        }\n",
    "    }\n",
    "    val event = commandQueue.enqueueWriteBuffer(weightDeviceBuffer, weightHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mreadWeightBuffer\u001b[39m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readWeightBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(weightDeviceBuffer, weightHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeWeightBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minputDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@476b8180"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputDeviceBuffer = dataDeviceBuffer.view(0, BatchSize * Width * Height * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mscoreDataDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@df27a5f"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val scoreDataDeviceBuffer = dataDeviceBuffer.view(BatchSize * Width * Height * (NumberOfCells - NumberOfClasses), BatchSize * Width * Height * NumberOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mscoreDeltaDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@612c62ba"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val scoreDeltaDeviceBuffer = deltaDeviceBuffer.view(BatchSize * Width * Height * (NumberOfCells - NumberOfClasses), BatchSize * Width * Height * NumberOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlossDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@306cf04b"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lossDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredictionDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@62ee9b30"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlabelDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mByte\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@3775f1c8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelDeviceBuffer = context.createUninitializedBuffer[Byte](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moutputLabelDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mByte\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@327316f2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outputLabelDeviceBuffer = context.createUninitializedBuffer[Byte](BatchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mplainFiberDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mShort\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@a06b743"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plainFiberDeviceBuffer = {\n",
    "    val fiberHostBuffer = MemoryUtil.memAllocShort(allFibers.length * 4)\n",
    "    try {\n",
    "        for (fiber <- allFibers) {\n",
    "            fiberHostBuffer.put(fiber.offsetX.toShort)\n",
    "            fiberHostBuffer.put(fiber.offsetY.toShort)\n",
    "            fiberHostBuffer.put(fiber.inputCellIndex.toShort)\n",
    "            fiberHostBuffer.put(fiber.outputCellIndex.toShort)\n",
    "        }\n",
    "        fiberHostBuffer.position(0)\n",
    "        context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "    } finally {\n",
    "        MemoryUtil.memFree(fiberHostBuffer)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mepochIndices\u001b[39m: \u001b[32mIterator\u001b[39m[\u001b[32mIndexedSeq\u001b[39m[\u001b[32mInt\u001b[39m]] = non-empty iterator"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val epochIndices = util.Random.shuffle(0 until NumberOfTrainingSamples: IndexedSeq[Int]).grouped(BatchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minputHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mFloatBuffer\u001b[39m = java.nio.DirectFloatBufferU[pos=0 lim=98304 cap=98304]\n",
       "\u001b[36mlabelArray\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mByte\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mlabelHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mByteBuffer\u001b[39m = java.nio.DirectByteBuffer[pos=0 lim=32 cap=32]\n",
       "\u001b[36mvarianceHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mFloatBuffer\u001b[39m = java.nio.DirectFloatBufferU[pos=0 lim=113 cap=113]\n",
       "\u001b[36mbiasHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mFloatBuffer\u001b[39m = java.nio.DirectFloatBufferU[pos=0 lim=113 cap=113]\n",
       "\u001b[36mimageSumDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@5f006cca\n",
       "\u001b[36msquareSumDeviceBuffer\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mBuffer\u001b[39m[\u001b[32mFloat\u001b[39m] = com.thoughtworks.compute.OpenCL$Buffer@2c74eb93\n",
       "\u001b[36mdataHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mFloatBuffer\u001b[39m = java.nio.DirectFloatBufferU[pos=0 lim=3702784 cap=3702784]\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteBiasBuffer\u001b[39m\n",
       "\u001b[36mforwardKernels\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mOpenCL\u001b[39m.\u001b[32mKernel\u001b[39m)] = \u001b[33mVector\u001b[39m(\n",
       "  (\u001b[32m3\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@48a0db64),\n",
       "  (\u001b[32m4\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@fc3d0dd),\n",
       "  (\u001b[32m5\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@4d91e565),\n",
       "  (\u001b[32m6\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@462324af),\n",
       "  (\u001b[32m7\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@896bcf4),\n",
       "  (\u001b[32m8\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@19c2c003),\n",
       "  (\u001b[32m9\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@5bbab493),\n",
       "  (\u001b[32m10\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@463f517),\n",
       "  (\u001b[32m11\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@39af9873),\n",
       "  (\u001b[32m12\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@3662959d),\n",
       "  (\u001b[32m13\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@3872b1ee),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputHostBuffer = MemoryUtil.memAllocFloat(inputDeviceBuffer.length)\n",
    "val labelArray = Array.ofDim[Byte](labelDeviceBuffer.length)\n",
    "val labelHostBuffer = MemoryUtil.memAlloc(labelDeviceBuffer.length)\n",
    "\n",
    "\n",
    "\n",
    "// Compute mean and bias for one cell\n",
    "\n",
    "val varianceHostBuffer = MemoryUtil.memAllocFloat(NumberOfCells)\n",
    "val biasHostBuffer = MemoryUtil.memAllocFloat(NumberOfCells)\n",
    "val imageSumDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)\n",
    "val squareSumDeviceBuffer = context.createUninitializedBuffer[Float](BatchSize)\n",
    "val dataHostBuffer = MemoryUtil.memAllocFloat(dataDeviceBuffer.length)\n",
    "\n",
    "def writeBiasBuffer() = {\n",
    "    val event = commandQueue.enqueueWriteBuffer(biasDeviceBuffer, biasHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}\n",
    "\n",
    "val forwardKernels = for (outputCellIndex <- NumberOfInputChannels until NumberOfCells) yield {\n",
    "    val fibers = fibersByOutputCellIndex(outputCellIndex)\n",
    "    val forwardKernel = program.createKernel(\"forward\")\n",
    "    forwardKernel.setArg(0, dataDeviceBuffer)\n",
    "    forwardKernel.setArg(1, weightDeviceBuffer)\n",
    "    forwardKernel.setArg(2, biasDeviceBuffer)\n",
    "    forwardKernel.setArg(3, Address(outputCellIndex))\n",
    "    forwardKernel.setArg(4, Address(fibers.length))\n",
    "    if (fibers.isEmpty) {\n",
    "        forwardKernel.setArg(5, Address(MemoryUtil.NULL))\n",
    "    } else {\n",
    "        val fiberHostBuffer = MemoryUtil.memAllocShort(fibers.length * 4)\n",
    "        val forwardFiberDeviceBuffer = try {\n",
    "            for (pair <- fibers) {\n",
    "                val (fiber, weightIndex) = pair\n",
    "                fiberHostBuffer.put(fiber.offsetX.toShort)\n",
    "                fiberHostBuffer.put(fiber.offsetY.toShort)\n",
    "                fiberHostBuffer.put(fiber.inputCellIndex.toShort)\n",
    "                fiberHostBuffer.put(weightIndex.toShort)\n",
    "            }\n",
    "            fiberHostBuffer.position(0)\n",
    "            context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "        } finally {\n",
    "            MemoryUtil.memFree(fiberHostBuffer)\n",
    "        }\n",
    "        // TODO: clean up plainFiberDeviceBuffer\n",
    "        forwardKernel.setArg(5, forwardFiberDeviceBuffer)\n",
    "    }\n",
    "    outputCellIndex -> forwardKernel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mfillImageHostBuffer\u001b[39m"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fillImageHostBuffer(batchIndices: IndexedSeq[Int]): Unit = {\n",
    "    val imageSize = 1 + Width * Height * NumberOfInputChannels\n",
    "    val imageArray = Array.ofDim[Byte](imageSize)\n",
    "    val channelArray = Array.ofDim[Float](Width * Height)\n",
    "    for ((trainingImageIndex, i) <- batchIndices.view.zipWithIndex) {\n",
    "        val trainingHostBuffer = trainingHostBuffers(trainingImageIndex / NumberOfTrainingSamplesPerFile)\n",
    "        val imageOffsetInFile = imageSize * (trainingImageIndex % NumberOfTrainingSamplesPerFile)\n",
    "        trainingHostBuffer.position(imageOffsetInFile)\n",
    "        trainingHostBuffer.get(imageArray)\n",
    "        labelArray(i) = imageArray(0)\n",
    "        for (channel <- 0 until NumberOfInputChannels) {\n",
    "            for (xy <- 0 until (Width * Height)) {\n",
    "                channelArray(xy) = ((imageArray(1 + channel * Width * Height + xy) & 0xFF).toFloat + 0.5f) / 256.0f\n",
    "            }\n",
    "            inputHostBuffer.position((channel * BatchSize + i) * Width * Height)\n",
    "            inputHostBuffer.put(channelArray)\n",
    "        }\n",
    "    }\n",
    "    inputHostBuffer.position(0)\n",
    "    labelHostBuffer.put(labelArray)\n",
    "    labelHostBuffer.position(0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteInputBuffer\u001b[39m"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def writeInputBuffer() = {\n",
    "    val event = commandQueue.enqueueWriteBuffer(inputDeviceBuffer, inputHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwriteLabelBuffer\u001b[39m"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def writeLabelBuffer() = {\n",
    "    val event = commandQueue.enqueueWriteBuffer(labelDeviceBuffer, labelHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mreadDataBuffer\u001b[39m"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readDataBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(dataDeviceBuffer, dataHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36madjustData\u001b[39m"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjustData(outputCellIndex: Int) = {\n",
    "    val fibers = fibersByOutputCellIndex(outputCellIndex)\n",
    "    val forwardSumKernel = program.createKernel(\"forward_sum\")\n",
    "    try {\n",
    "        forwardSumKernel.setArg(0, dataDeviceBuffer)\n",
    "        forwardSumKernel.setArg(1, weightDeviceBuffer)\n",
    "        forwardSumKernel.setArg(2, Address(outputCellIndex))\n",
    "        forwardSumKernel.setArg(3, Address(fibers.length))\n",
    "        assert(fibers.nonEmpty, \"fibers.nonEmpty\")\n",
    "\n",
    "        val slicePlainFiberDeviceBuffer = {\n",
    "            val fiberHostBuffer = MemoryUtil.memAllocShort(fibers.length * 4)\n",
    "            try {\n",
    "                for (pair <- fibers) {\n",
    "                    val (fiber, weightIndex) = pair\n",
    "                    fiberHostBuffer.put(fiber.offsetX.toShort)\n",
    "                    fiberHostBuffer.put(fiber.offsetY.toShort)\n",
    "                    fiberHostBuffer.put(fiber.inputCellIndex.toShort)\n",
    "                    fiberHostBuffer.put(weightIndex.toShort)\n",
    "                }\n",
    "                fiberHostBuffer.position(0)\n",
    "                context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "            } finally {\n",
    "                MemoryUtil.memFree(fiberHostBuffer)\n",
    "            }\n",
    "        }\n",
    "        try {\n",
    "            forwardSumKernel.setArg(4, slicePlainFiberDeviceBuffer)\n",
    "            forwardSumKernel.setArg(5, imageSumDeviceBuffer)\n",
    "            val event = commandQueue.enqueueNDRangeKernel(forwardSumKernel, Seq(GlobalWorkSizeOnlyDimension(Address(BatchSize))))\n",
    "            try {\n",
    "                event.waitForComplete.blockingAwait\n",
    "            } finally {\n",
    "                event.close()\n",
    "            }\n",
    "        } finally {\n",
    "            slicePlainFiberDeviceBuffer.close()\n",
    "        }\n",
    "    } finally {\n",
    "        forwardSumKernel.close()\n",
    "    }\n",
    "\n",
    "    val imageSumArray = {\n",
    "        val imageSumHostBuffer = MemoryUtil.memAllocFloat(imageSumDeviceBuffer.length)\n",
    "        try {\n",
    "            val event = commandQueue.enqueueReadBuffer(imageSumDeviceBuffer, imageSumHostBuffer)\n",
    "            try {\n",
    "                event.waitForComplete.blockingAwait\n",
    "            } finally {\n",
    "                event.close()\n",
    "            }\n",
    "\n",
    "            val array = Array.ofDim[Float](imageSumHostBuffer.remaining)\n",
    "            imageSumHostBuffer.get(array)\n",
    "            array\n",
    "        } finally {\n",
    "            MemoryUtil.memFree(imageSumHostBuffer)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val outputMean: Float = imageSumArray.sum / (Width * Height * BatchSize)\n",
    "\n",
    "    val squareSumKernel = program.createKernel(\"square_sum\")\n",
    "    try {\n",
    "        squareSumKernel.setArg(0, dataDeviceBuffer)\n",
    "        squareSumKernel.setArg(1, outputMean)\n",
    "        squareSumKernel.setArg(2, Address(outputCellIndex))\n",
    "        squareSumKernel.setArg(3, squareSumDeviceBuffer)\n",
    "        val event = commandQueue.enqueueNDRangeKernel(squareSumKernel, Seq(GlobalWorkSizeOnlyDimension(Address(BatchSize))))\n",
    "        try {\n",
    "            event.waitForComplete.blockingAwait\n",
    "        } finally {\n",
    "            event.close()\n",
    "        }\n",
    "\n",
    "    } finally {\n",
    "        squareSumKernel.close()\n",
    "    }\n",
    "\n",
    "    val squareSumArray = {\n",
    "        val squareSumHostBuffer = MemoryUtil.memAllocFloat(squareSumDeviceBuffer.length)\n",
    "        try {\n",
    "            val event = commandQueue.enqueueReadBuffer(squareSumDeviceBuffer, squareSumHostBuffer)\n",
    "            try {\n",
    "                event.waitForComplete.blockingAwait\n",
    "            } finally {\n",
    "                event.close()\n",
    "            }\n",
    "\n",
    "            val array = Array.ofDim[Float](squareSumHostBuffer.remaining)\n",
    "            squareSumHostBuffer.get(array)\n",
    "            array\n",
    "        } finally {\n",
    "            MemoryUtil.memFree(squareSumHostBuffer)\n",
    "        }\n",
    "    }\n",
    "    val variance = math.sqrt(squareSumArray.sum / (Width * Height * BatchSize)).toFloat\n",
    "    assert(variance > 0.0f, \"variance > 0.0f\")\n",
    "    varianceHostBuffer.put(outputCellIndex, variance)\n",
    "    val bias: Float = -outputMean / variance\n",
    "    biasHostBuffer.put(outputCellIndex, bias)\n",
    "    if (outputCellIndex == 3) {\n",
    "        println(s\"variance: $variance\")\n",
    "        println(s\"mean: $outputMean\")\n",
    "        println(s\"bias: $bias\")\n",
    "        readDataBuffer()\n",
    "        println(\"before adjust\")\n",
    "        val start = (3 * BatchSize) * Width * Height\n",
    "        (start until start + BatchSize * Width * Height by 10000).map(dataHostBuffer.get).foreach(println)\n",
    "    }\n",
    "\n",
    "    val adjustDataKernel = program.createKernel(\"adjust_data\")\n",
    "    try {\n",
    "        adjustDataKernel.setArg(0, dataDeviceBuffer)\n",
    "        adjustDataKernel.setArg(1, Address(outputCellIndex))\n",
    "        adjustDataKernel.setArg(2, variance)\n",
    "        adjustDataKernel.setArg(3, outputMean)\n",
    "        val event = commandQueue.enqueueNDRangeKernel(\n",
    "            adjustDataKernel, \n",
    "            Seq(\n",
    "                GlobalWorkSizeOnlyDimension(Address(BatchSize)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Width)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Height))\n",
    "            )\n",
    "        )\n",
    "        try {\n",
    "            event.waitForComplete.blockingAwait\n",
    "        } finally {\n",
    "            event.close()\n",
    "        }\n",
    "\n",
    "    } finally {\n",
    "        adjustDataKernel.close()\n",
    "    }\n",
    "\n",
    "    if (outputCellIndex == 3) {\n",
    "        readDataBuffer()\n",
    "        println(\"after adjust:\")\n",
    "        val start = (3 * BatchSize) * Width * Height\n",
    "        (start until start + BatchSize * Width * Height by 10000).map(dataHostBuffer.get).foreach(println)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36madjustBias\u001b[39m"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36madjustWeight\u001b[39m"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjustWeight() = {\n",
    "    val varianceDeviceBuffer = context.createBufferFrom(varianceHostBuffer)\n",
    "    try {\n",
    "        val adjustWeightKernel = program.createKernel(\"adjust_weight\")\n",
    "        try {\n",
    "            adjustWeightKernel.setArg(0, weightDeviceBuffer)\n",
    "            adjustWeightKernel.setArg(1, varianceDeviceBuffer)\n",
    "            adjustWeightKernel.setArg(2, plainFiberDeviceBuffer)\n",
    "            val event = commandQueue.enqueueNDRangeKernel(adjustWeightKernel, Seq(GlobalWorkSizeOnlyDimension(Address(allFibers.length))))\n",
    "            try {\n",
    "                event.waitForComplete.blockingAwait\n",
    "            } finally {\n",
    "                event.close()\n",
    "            }\n",
    "        } finally {\n",
    "            adjustWeightKernel.close()\n",
    "        }\n",
    "    } finally {\n",
    "        varianceDeviceBuffer.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mbatchNormalize\u001b[39m"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batchNormalize() = {\n",
    "\n",
    "    for (outputCellIndex <- NumberOfInputChannels until NumberOfCells) {\n",
    "        adjustData(outputCellIndex)\n",
    "    }\n",
    "    writeBiasBuffer()\n",
    "    adjustBias()\n",
    "    adjustWeight()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mforward\u001b[39m"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward() = {\n",
    "    for ((_, forwardKernel) <- forwardKernels) {\n",
    "        val event = commandQueue.enqueueNDRangeKernel(\n",
    "            forwardKernel,\n",
    "            Seq(\n",
    "                GlobalWorkSizeOnlyDimension(Address(BatchSize)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Width)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Height))\n",
    "            )\n",
    "        )\n",
    "        try {\n",
    "            event.waitForComplete.blockingAwait\n",
    "        } finally {\n",
    "            event.close()\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainLossKernel\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mKernel\u001b[39m = com.thoughtworks.compute.OpenCL$Kernel@1e4597cb"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainLossKernel = program.createKernel(\"train_loss\")\n",
    "trainLossKernel.setArg(0, scoreDataDeviceBuffer)\n",
    "trainLossKernel.setArg(1, scoreDeltaDeviceBuffer)\n",
    "trainLossKernel.setArg(2, labelDeviceBuffer)\n",
    "trainLossKernel.setArg(3, outputLabelDeviceBuffer)\n",
    "trainLossKernel.setArg(4, lossDeviceBuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainLoss\u001b[39m"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainLoss() = {\n",
    "    val event = commandQueue.enqueueNDRangeKernel(\n",
    "        trainLossKernel,\n",
    "        Seq(GlobalWorkSizeOnlyDimension(Address(BatchSize)))\n",
    "    )\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36moutputLabelHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mByteBuffer\u001b[39m = java.nio.DirectByteBuffer[pos=0 lim=32 cap=32]\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mreadOutputLabelBuffer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36maccuracyRate\u001b[39m"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outputLabelHostBuffer = MemoryUtil.memAlloc(BatchSize)\n",
    "\n",
    "def readOutputLabelBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(outputLabelDeviceBuffer, outputLabelHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "} \n",
    "def accuracyRate = {\n",
    "    readOutputLabelBuffer()\n",
    "    val outputLabelArray = Array.ofDim[Byte](outputLabelHostBuffer.remaining)\n",
    "    outputLabelHostBuffer.get(outputLabelArray)\n",
    "    outputLabelHostBuffer.position(0)\n",
    "    outputLabelArray.view.zip(labelArray).count {\n",
    "        case (outputLabel, expectedLabel) =>\n",
    "            outputLabel == expectedLabel\n",
    "    }.toDouble / outputLabelArray.length\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlossHostBuffer\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mFloatBuffer\u001b[39m = java.nio.DirectFloatBufferU[pos=0 lim=32 cap=32]\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mreadLossBuffer\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmeanLoss\u001b[39m"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lossHostBuffer = MemoryUtil.memAllocFloat(BatchSize)\n",
    "\n",
    "def readLossBuffer() = {\n",
    "    val event = commandQueue.enqueueReadBuffer(lossDeviceBuffer, lossHostBuffer)\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }\n",
    "}\n",
    "\n",
    "def meanLoss = {\n",
    "    val lossArray = Array.ofDim[Float](BatchSize)\n",
    "    lossHostBuffer.get(lossArray)\n",
    "    lossHostBuffer.position(0)\n",
    "    lossArray.sum / NumberOfClasses / BatchSize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbackwardKernels\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mOpenCL\u001b[39m.\u001b[32mKernel\u001b[39m)] = \u001b[33mVector\u001b[39m(\n",
       "  (\u001b[32m0\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@38df3900),\n",
       "  (\u001b[32m1\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@2ebad4cd),\n",
       "  (\u001b[32m2\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@3c6339ad),\n",
       "  (\u001b[32m3\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@158fcdd8),\n",
       "  (\u001b[32m4\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@5459f150),\n",
       "  (\u001b[32m5\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@2cbd5baa),\n",
       "  (\u001b[32m6\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@9b6b1c1),\n",
       "  (\u001b[32m7\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@62bc5c22),\n",
       "  (\u001b[32m8\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@79f4e254),\n",
       "  (\u001b[32m9\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@3fd286cb),\n",
       "  (\u001b[32m10\u001b[39m, com.thoughtworks.compute.OpenCL$Kernel@3560049),\n",
       "\u001b[33m...\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mbackward\u001b[39m"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val backwardKernels = for (inputCellIndex <- 0 until (NumberOfInputChannels + NumberOfHiddenCells)) yield {\n",
    "    val fibers = fibersByInputCellIndex(inputCellIndex)\n",
    "    val backwardKernel = program.createKernel(\"backward\")\n",
    "    // TODO: clean\n",
    "    backwardKernel.setArg(0, deltaDeviceBuffer)\n",
    "    backwardKernel.setArg(1, weightDeviceBuffer)\n",
    "    backwardKernel.setArg(2, Address(inputCellIndex))\n",
    "    backwardKernel.setArg(3, Address(fibers.length))\n",
    "    if (fibers.isEmpty) {\n",
    "        backwardKernel.setArg(4, Address(MemoryUtil.NULL))\n",
    "    } else {\n",
    "        val fiberHostBuffer = MemoryUtil.memAllocShort(fibers.length * 4)\n",
    "        val backwardFiberDeviceBuffer = try {\n",
    "            for (pair <- fibers) {\n",
    "                val (fiber, weightIndex) = pair\n",
    "                fiberHostBuffer.put((-fiber.offsetX).toShort)\n",
    "                fiberHostBuffer.put((-fiber.offsetY).toShort)\n",
    "                fiberHostBuffer.put(fiber.outputCellIndex.toShort)\n",
    "                fiberHostBuffer.put(weightIndex.toShort)\n",
    "            }\n",
    "            fiberHostBuffer.position(0)\n",
    "            context.createBufferFrom[Short, java.nio.ShortBuffer](fiberHostBuffer)\n",
    "        } finally {\n",
    "            MemoryUtil.memFree(fiberHostBuffer)\n",
    "        }\n",
    "        backwardKernel.setArg(4, backwardFiberDeviceBuffer)\n",
    "    }\n",
    "    inputCellIndex -> backwardKernel\n",
    "}\n",
    "\n",
    "def backward() = {\n",
    "    for ((_, backwardKernel) <- backwardKernels.reverseIterator) {\n",
    "        val event = commandQueue.enqueueNDRangeKernel(\n",
    "            backwardKernel,\n",
    "            Seq(\n",
    "                GlobalWorkSizeOnlyDimension(Address(BatchSize)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Width)),\n",
    "                GlobalWorkSizeOnlyDimension(Address(Height))\n",
    "            )\n",
    "        )\n",
    "        try {\n",
    "            event.waitForComplete.blockingAwait\n",
    "        } finally {\n",
    "            event.close()\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mupdateBiasKernel\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mKernel\u001b[39m = com.thoughtworks.compute.OpenCL$Kernel@2ce12b92\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupdateBias\u001b[39m\n",
       "\u001b[36mupdateWeightKernel\u001b[39m: \u001b[32mOpenCL\u001b[39m.\u001b[32mKernel\u001b[39m = com.thoughtworks.compute.OpenCL$Kernel@757eec26\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mupdateWeight\u001b[39m"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val updateBiasKernel = program.createKernel(\"update_bias\")\n",
    "updateBiasKernel.setArg(0, deltaDeviceBuffer)\n",
    "updateBiasKernel.setArg(1, biasDeviceBuffer)\n",
    "\n",
    "def updateBias() = {\n",
    "    val event = commandQueue.enqueueNDRangeKernel(\n",
    "        updateBiasKernel,\n",
    "        Seq(GlobalWorkSizeOnlyDimension(Address(NumberOfCells)))\n",
    "    )\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }    \n",
    "}\n",
    "\n",
    "\n",
    "val updateWeightKernel = {\n",
    "    val kernel = program.createKernel(\"update_weight\")\n",
    "    kernel.setArg(0, dataDeviceBuffer)\n",
    "    kernel.setArg(1, deltaDeviceBuffer)\n",
    "    kernel.setArg(2, weightDeviceBuffer)\n",
    "    kernel.setArg(3, plainFiberDeviceBuffer)\n",
    "    kernel\n",
    "}\n",
    "\n",
    "def updateWeight() = {\n",
    "    val event = commandQueue.enqueueNDRangeKernel(\n",
    "        updateWeightKernel,\n",
    "        Seq(GlobalWorkSizeOnlyDimension(Address(allFibers.length)))\n",
    "    )\n",
    "    try {\n",
    "        event.waitForComplete.blockingAwait\n",
    "    } finally {\n",
    "        event.close()\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbatchIndices\u001b[39m: \u001b[32mIndexedSeq\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[32m7378\u001b[39m,\n",
       "  \u001b[32m31932\u001b[39m,\n",
       "  \u001b[32m31245\u001b[39m,\n",
       "  \u001b[32m40759\u001b[39m,\n",
       "  \u001b[32m19823\u001b[39m,\n",
       "  \u001b[32m27260\u001b[39m,\n",
       "  \u001b[32m44598\u001b[39m,\n",
       "  \u001b[32m9622\u001b[39m,\n",
       "  \u001b[32m27146\u001b[39m,\n",
       "  \u001b[32m24927\u001b[39m,\n",
       "  \u001b[32m48049\u001b[39m,\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    val batchIndices = epochIndices.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    fillImageHostBuffer(batchIndices)\n",
    "    writeInputBuffer()\n",
    "    writeLabelBuffer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance: 1.3979331\n",
      "mean: 1.4665403\n",
      "bias: -1.0490776\n",
      "before adjust\n",
      "0.6307578\n",
      "2.7398987\n",
      "1.6675332\n",
      "2.097892\n",
      "after adjust:\n",
      "0.0\n",
      "0.91088647\n",
      "0.14377856\n",
      "0.45163226\n"
     ]
    }
   ],
   "source": [
    "{{\n",
    "    fillImageHostBuffer(batchIndices)\n",
    "    writeInputBuffer()\n",
    "    writeLabelBuffer()\n",
    "    batchNormalize()\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance: 1.0\n",
      "mean: 1.0490775\n",
      "bias: -1.0490775\n",
      "before adjust\n",
      "0.4512074\n",
      "1.959964\n",
      "1.1928562\n",
      "1.5007099\n",
      "after adjust:\n",
      "0.0\n",
      "0.9108865\n",
      "0.14377868\n",
      "0.45163238\n"
     ]
    }
   ],
   "source": [
    "adjustData(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjustWeight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeBiasBuffer()\n",
    "adjustBias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance: 1.0\n",
      "mean: 1.0490775\n",
      "bias: -1.0490775\n",
      "before adjust\n",
      "0.4512074\n",
      "1.959964\n",
      "1.1928562\n",
      "1.5007099\n",
      "after adjust:\n",
      "0.0\n",
      "0.9108865\n",
      "0.14377868\n",
      "0.45163238\n"
     ]
    }
   ],
   "source": [
    "adjustData(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasHostBuffer.get(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightHostBuffer.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightHostBuffer.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightHostBuffer.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightHostBuffer.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "readWeightBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "// // Loss in Scala\n",
    "// readScoreDataBuffer()\n",
    "// val label = labelHostBuffer.get(0)\n",
    "// val losses = for (currentClass <- 0 until NumberOfClasses) yield {\n",
    "//     val start = ((currentClass) * BatchSize) * Width * Height\n",
    "//     if (label == currentClass) {\n",
    "//         val s = for(i <- start until start + BatchSize * Width * Height view) yield {\n",
    "//             val pixelScore = scoreDataHostBuffer.get(i)\n",
    "//             val margin = (pixelScore - 2.0f)\n",
    "//             4.5 * margin * margin\n",
    "//         }\n",
    "//         s.sum\n",
    "//     } else {\n",
    "//         val s = for(i <- start until start + BatchSize * Width * Height view) yield {\n",
    "//             val pixelScore = scoreDataHostBuffer.get(i)\n",
    "//             pixelScore * pixelScore\n",
    "//         }\n",
    "//         s.sum\n",
    "//     }\n",
    "// }\n",
    "// val scalaMeanLoss = losses.sum / NumberOfClasses / BatchSize / Width / Height\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeWeightBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchNormalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchNormalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLoss()\n",
    "    backward()\n",
    "    updateBias()\n",
    "    updateWeight()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    batchNormalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((batchIndices, i) <- epochIndices.zipWithIndex) {\n",
    "    fillImageHostBuffer(batchIndices)\n",
    "    writeInputBuffer()\n",
    "    writeLabelBuffer()\n",
    "//     if ((i % 2) == 0) {\n",
    "//         batchNormalize()\n",
    "//     } \n",
    "    forward()\n",
    "    trainLoss()\n",
    "    (i % 100) match {\n",
    "        case 0 | 99 =>\n",
    "            println(s\"iteration $i, loss=$meanLoss, accuracy rate=$accuracyRate\")\n",
    "            accuracyRate\n",
    "        case _ =>\n",
    "    }\n",
    "    readLossBuffer()\n",
    "    backward()\n",
    "    updateBias()\n",
    "    updateWeight()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "// // val scoreDataHostBuffer = MemoryUtil.memAllocFloat(scoreDataDeviceBuffer.length)\n",
    "\n",
    "// // def readScoreDataBuffer() = {\n",
    "// //     val event = commandQueue.enqueueReadBuffer(scoreDataDeviceBuffer, scoreDataHostBuffer)\n",
    "// //     try {\n",
    "// //         event.waitForComplete.blockingAwait\n",
    "// //     } finally {\n",
    "// //         event.close()\n",
    "// //     }\n",
    "// // }\n",
    "\n",
    "// forward()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// // println(meanLoss)\n",
    "\n",
    "\n",
    "\n",
    "// // readOutputLabelBuffer()\n",
    "\n",
    "// // (0 until outputLabelHostBuffer.remaining).map(outputLabelHostBuffer.get).foreach(println)\n",
    "\n",
    "// // labelHostBuffer.get(0)\n",
    "\n",
    "// // readScoreDataBuffer()\n",
    "\n",
    "// // val scoreDeltaDeviceBuffer2 = context.createUninitializedBuffer[Float](10240)\n",
    "// // def trainLoss2() = {\n",
    "// //     val trainLossKernel2 = program.createKernel(\"train_loss\")\n",
    "// //     try {\n",
    "// //         trainLossKernel.setArg(0, scoreDataDeviceBuffer)\n",
    "// //         trainLossKernel.setArg(1, scoreDeltaDeviceBuffer2)\n",
    "// //         trainLossKernel.setArg(2, labelDeviceBuffer)\n",
    "// //         trainLossKernel.setArg(3, outputLabelDeviceBuffer)\n",
    "// //         trainLossKernel.setArg(4, lossDeviceBuffer)\n",
    "// //         val event = commandQueue.enqueueNDRangeKernel(\n",
    "// //             trainLossKernel,\n",
    "// //             Seq(GlobalWorkSizeOnlyDimension(Address(BatchSize)))\n",
    "// //         )\n",
    "// //         try {\n",
    "// //             event.waitForComplete.blockingAwait\n",
    "// //         } finally {\n",
    "// //             event.close()\n",
    "// //         }\n",
    "// //     } finally {\n",
    "// //         trainLossKernel2.close()\n",
    "// //     }\n",
    "// // }\n",
    "\n",
    "// // trainLoss2()\n",
    "\n",
    "// // val scoreDeltaHostBuffer2 = MemoryUtil.memAllocFloat(10240)\n",
    "\n",
    "// // def readScoreDeltaBuffer2() = {\n",
    "// //     val event = commandQueue.enqueueReadBuffer(scoreDeltaDeviceBuffer2, scoreDeltaHostBuffer2)\n",
    "// //     try {\n",
    "// //         event.waitForComplete.blockingAwait\n",
    "// //     } finally {\n",
    "// //         event.close()\n",
    "// //     }\n",
    "// // }\n",
    "\n",
    "// // readScoreDataBuffer()\n",
    "\n",
    "// // val start = (0 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// // val start = (2 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// // readScoreDataBuffer()\n",
    "\n",
    "// // val start = (0 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// // val start = (2 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// // readScoreDeltaBuffer2()\n",
    "\n",
    "// // val start = (0 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDeltaHostBuffer2.get).foreach(println)\n",
    "\n",
    "// // readScoreDeltaBuffer()\n",
    "\n",
    "// // val start = (1 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDeltaHostBuffer.get).foreach(println)\n",
    "\n",
    "\n",
    "\n",
    "// // {{\n",
    "// //     val start = (0 * BatchSize) * Width * Height\n",
    "// //     (start until start + BatchSize * Width * Height).map(scoreDeltaHostBuffer.get).foreach(println)\n",
    "// // }}\n",
    "\n",
    "\n",
    "\n",
    "// // readScoreDeltaBuffer()\n",
    "\n",
    "// // val start = (1 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDeltaHostBuffer.get).foreach(println)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// // val a = {\n",
    "// //     val start = (0 * BatchSize) * Width * Height\n",
    "// //     (start until start + BatchSize * Width * Height).map(scoreDeltaHostBuffer.get)\n",
    "// // }\n",
    "// // // readDataBuffer()\n",
    "\n",
    "// // a.slice(650, 700).zip(650 until 700).foreach(println)\n",
    "\n",
    "// // readDataBuffer()\n",
    "// // val start = (3 * BatchSize + 1) * Width * Height\n",
    "// // (start until start + Width * Height).map(dataHostBuffer.get).foreach(println)\n",
    "\n",
    "// // (3 * BatchSize * Width * Height until 4 * BatchSize * Width * Height).view.map(dataHostBuffer.get).sum\n",
    "\n",
    "// // val dataHostBuffer = MemoryUtil.memAllocFloat(dataDeviceBuffer.length)\n",
    "\n",
    "// // def readDataBuffer() = {\n",
    "// //     val event = commandQueue.enqueueReadBuffer(dataDeviceBuffer, dataHostBuffer)\n",
    "// //     try {\n",
    "// //         event.waitForComplete.blockingAwait\n",
    "// //     } finally {\n",
    "// //         event.close()\n",
    "// //     }\n",
    "// // }\n",
    "\n",
    "// // readDataBuffer()\n",
    "\n",
    "// // TODO: exclude input delta\n",
    "\n",
    "// // readDeltaBuffer()\n",
    "// // val start = (3 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(deltaHostBuffer.get).foreach(println)\n",
    "\n",
    "// // readDeltaBuffer()\n",
    "\n",
    "// // val start = (0 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height by 10).map(deltaHostBuffer.get).foreach(println)\n",
    "\n",
    "\n",
    "\n",
    "// backward()\n",
    "\n",
    "// // readDeltaBuffer()\n",
    "\n",
    "// // // val start = (3 * BatchSize) * Width * Height\n",
    "// // // (start until start + BatchSize * Width * Height by 100).map(deltaHostBuffer.get).foreach(println)\n",
    "\n",
    "// // val start = (0 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height by 100).map(deltaHostBuffer.get).foreach(println)\n",
    "\n",
    "// updateBias()\n",
    "\n",
    "// updateWeight()\n",
    "\n",
    "\n",
    "\n",
    "// forward()\n",
    "\n",
    "// // // Loss in Scala\n",
    "// // readScoreDataBuffer()\n",
    "// // val label = labelHostBuffer.get(0)\n",
    "// // val losses = for (currentClass <- 0 until NumberOfClasses) yield {\n",
    "// //     val start = ((currentClass) * BatchSize) * Width * Height\n",
    "// //     if (label == currentClass) {\n",
    "// //         val s = for(i <- start until start + BatchSize * Width * Height view) yield {\n",
    "// //             val pixelScore = scoreDataHostBuffer.get(i)\n",
    "// //             val margin = (pixelScore - 2.0f)\n",
    "// //             4.5 * margin * margin\n",
    "// //         }\n",
    "// //         s.sum\n",
    "// //     } else {\n",
    "// //         val s = for(i <- start until start + BatchSize * Width * Height view) yield {\n",
    "// //             val pixelScore = scoreDataHostBuffer.get(i)\n",
    "// //             pixelScore * pixelScore\n",
    "// //         }\n",
    "// //         s.sum\n",
    "// //     }\n",
    "// // }\n",
    "// // val scalaMeanLoss = losses.sum / NumberOfClasses / BatchSize / Width / Height\n",
    "\n",
    "// // readWeightBuffer()\n",
    "\n",
    "// // weightHostBuffer.remaining\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// for (i <- 0 until 1000) {\n",
    "//     forward()\n",
    "//     trainLoss()\n",
    "//     readLossBuffer()\n",
    "//     if (i % 100 == 0) {\n",
    "//         println(s\"iteration $i, loss=$meanLoss, accuracy rate=$accuracyRate\")\n",
    "//         accuracyRate\n",
    "//     }\n",
    "//     backward()\n",
    "//     updateBias()\n",
    "//     updateWeight()\n",
    "// }\n",
    "\n",
    "// for (i <- 0 until 1000) {\n",
    "//     forward()\n",
    "//     trainLoss()\n",
    "//     readLossBuffer()\n",
    "//     if (i % 100 == 0) {\n",
    "//         println(s\"iteration $i, loss=$meanLoss, accuracy rate=$accuracyRate\")\n",
    "//         accuracyRate\n",
    "//     }\n",
    "//     backward()\n",
    "//     updateBias()\n",
    "//     updateWeight()\n",
    "// }\n",
    "\n",
    "// for (i <- 0 until 10000) {\n",
    "//     forward()\n",
    "//     trainLoss()\n",
    "//     readLossBuffer()\n",
    "//     if (i % 100 == 0) {\n",
    "//         println(s\"iteration $i, loss=$meanLoss, accuracy rate=$accuracyRate\")\n",
    "//         accuracyRate\n",
    "//     }\n",
    "//     backward()\n",
    "//     updateBias()\n",
    "//     updateWeight()\n",
    "// }\n",
    "\n",
    "\n",
    "\n",
    "// readLossBuffer()\n",
    "//     val lossArray = Array.ofDim[Float](BatchSize)\n",
    "//     lossHostBuffer.get(lossArray)\n",
    "//     lossHostBuffer.position(0)\n",
    "\n",
    "// // forward()\n",
    "// // trainLoss()\n",
    "// // readLossBuffer()\n",
    "// // println(meanLoss)\n",
    "// // backward()\n",
    "// // updateWeight()\n",
    "\n",
    "// // readScoreDataBuffer()\n",
    "// // val start = (4 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// // forward()\n",
    "// // trainLoss()\n",
    "// // readLossBuffer()\n",
    "// // println(meanLoss)\n",
    "// // backward()\n",
    "// // updateWeight()\n",
    "\n",
    "// // readScoreDataBuffer()\n",
    "// // val start = (9 * BatchSize) * Width * Height\n",
    "// // (start until start + BatchSize * Width * Height).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// readScoreDataBuffer()\n",
    "\n",
    "// (0 until scoreDataHostBuffer.remaining by 100).map(scoreDataHostBuffer.get).foreach(println)\n",
    "\n",
    "// labelArray\n",
    "\n",
    "//     readOutputLabelBuffer()\n",
    "//     val outputLabelArray = Array.ofDim[Byte](outputLabelHostBuffer.remaining)\n",
    "//     outputLabelHostBuffer.get(outputLabelArray)\n",
    "//     outputLabelHostBuffer.position(0)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12.2",
   "language": "scala",
   "name": "scala-2.12.2"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala212",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
