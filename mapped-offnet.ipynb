{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "training_data, testing_data = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = np.max(testing_data[1]) + 1\n",
    "number_of_input_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_layers = 64 # 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lod_channels = [8, 8, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_samples_per_fiber():\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OffsetIndex = IntEnum(\"OffsetIndex\", names=[\"OFFSET_X\", \"OFFSET_Y\"], start=0)\n",
    "ChannelIndex = IntEnum(\"ChannelIndex\", names=[\"TARGET_CHANNEL\", \"SOURCE_CHANNEL\"], start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_variable_scope = tf.get_variable_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a  = tf.constant([[0,2],[5,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiber(number_of_target_channels, number_of_source_channels, source_layer):\n",
    "    def generate_channel_indices():\n",
    "        for target_channel_index in range(number_of_target_channels):\n",
    "            for source_channel_index in range(number_of_source_channels):\n",
    "                number_of_samples_per_fiber = get_number_of_samples_per_fiber()\n",
    "                for fiber_index in range(number_of_samples_per_fiber):\n",
    "                    yield (target_channel_index, source_channel_index)\n",
    "    channel_indices = tf.get_variable(name=\"channel_indices\", initializer=tuple(generate_channel_indices()), trainable=False)\n",
    "    target_channel_indices, source_channel_indices = tf.unstack(channel_indices, axis=1)\n",
    "    number_of_sample_points, number_of_channel_indices = channel_indices.shape\n",
    "    assert number_of_channel_indices == len(ChannelIndex.__members__)\n",
    "    offset_xys = tf.get_variable(name=\"offset_xy\", trainable=False, initializer=tf.random_normal_initializer(stddev=3), dtype=tf.float32, shape=(number_of_sample_points, len(OffsetIndex.__members__)))\n",
    "    weights = tf.get_variable(name=\"weight\", initializer=tf.glorot_normal_initializer(), dtype=tf.float32, shape=(number_of_sample_points, ))\n",
    "    def weighted(triple):\n",
    "        source_index, offset_xy, weight = triple\n",
    "        return weight * tf.contrib.image.translate(source_layer[:, :, :, source_index], translations=offset_xy)\n",
    "    mapped = tf.map_fn(weighted, (source_channel_indices, offset_xys, weights), dtype=tf.float32)\n",
    "\n",
    "    batch_size, width, height, number_of_source_channels = source_layer.shape\n",
    "    mapped.set_shape((number_of_sample_points, batch_size, width, height))\n",
    "\n",
    "    with tf.contrib.compiler.jit.experimental_jit_scope():\n",
    "        return tf.transpose(\n",
    "            tf.unsorted_segment_sum(\n",
    "                mapped,\n",
    "                segment_ids=target_channel_indices,\n",
    "                num_segments=number_of_target_channels\n",
    "            ),\n",
    "            perm=(1, 2, 3, 0)  \n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params, config):\n",
    "    input_shape = features.shape\n",
    "    def lod_size(i):\n",
    "        scale = 2 ** i\n",
    "        return input_shape[1] // tf.Dimension(scale), input_shape[2] // tf.Dimension(scale)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def input_layer(current_lod):\n",
    "        with tf.variable_scope(root_variable_scope), tf.variable_scope(f\"scale_{current_lod}\"), tf.name_scope(f\"scale_{current_lod}/\"):\n",
    "            if current_lod == 0:\n",
    "                return tf.expand_dims(tf.cast(features, tf.float32), axis=3) / 255.0\n",
    "            else:\n",
    "                # Pooling\n",
    "    #             tf.nn.avg_pool(\n",
    "    #                 value=layer(i, lod, current_lod - 1, channel),\n",
    "    #                 ksize=[1, 2, 2, 1],\n",
    "    #                 strides=[1, 1, 1, 1],\n",
    "    #                 padding='SAME'\n",
    "    #             )\n",
    "                return tf.image.resize_bilinear(\n",
    "                    images=input_layer(current_lod - 1),\n",
    "                    size=lod_size(current_lod),\n",
    "                    align_corners=False,\n",
    "                )\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def layer(target_layer_index, preferred_lod, current_lod):\n",
    "        \"\"\"Return a list of tensor of shape batch_size ⨉ lod_size(height) ⨉ lod_size(width) ⨉ channel\n",
    "\n",
    "        The list size is sum(lod_channels)\n",
    "        \"\"\"\n",
    "        with tf.variable_scope(root_variable_scope), tf.variable_scope(f\"layer_{target_layer_index}\"), tf.name_scope(f\"layer_{target_layer_index}/\"):\n",
    "            if current_lod == preferred_lod:\n",
    "                number_of_target_channels = lod_channels[preferred_lod]\n",
    "                with tf.variable_scope(f\"lod_{preferred_lod}\"):\n",
    "                    def source_layer_mapper(source_layer_index):\n",
    "                        with tf.variable_scope(f\"weighted_layer_{source_layer_index}\"):\n",
    "                            def source_lod_mapper(source_lod, number_of_source_channels):\n",
    "                                with tf.variable_scope(f\"weighted_lod_{source_lod}\"):\n",
    "                                    return fiber(\n",
    "                                        number_of_target_channels=number_of_target_channels,\n",
    "                                        number_of_source_channels=number_of_source_channels,\n",
    "                                        source_layer=layer(source_layer_index, source_lod, current_lod)\n",
    "                                    )\n",
    "                            return sum(source_lod_mapper(source_lod, number_of_source_channels)\n",
    "                                       for source_lod, number_of_source_channels in enumerate(lod_channels))\n",
    "                    channel_scores = sum(map(source_layer_mapper, range(target_layer_index)))\n",
    "                    bias = tf.get_variable(name=\"bias\", initializer=tf.zeros_initializer(), dtype=tf.float32, shape=(1, 1, 1, number_of_target_channels))\n",
    "                    with tf.variable_scope(\"weighted_input\"):\n",
    "                        input_fiber = fiber(number_of_target_channels=number_of_target_channels,\n",
    "                                            number_of_source_channels=number_of_input_channels,\n",
    "                                            source_layer=input_layer(current_lod))\n",
    "                        return bias + input_fiber + channel_scores\n",
    "            elif preferred_lod < current_lod:\n",
    "                # Pooling\n",
    "    #             tf.nn.avg_pool(\n",
    "    #                 value=layer(i, lod, current_lod - 1, channel),\n",
    "    #                 ksize=[1, 2, 2, 1],\n",
    "    #                 strides=[1, 1, 1, 1],\n",
    "    #                 padding='SAME'\n",
    "    #             )\n",
    "                return tf.image.resize_bilinear(\n",
    "                    images=layer(target_layer_index, preferred_lod, current_lod - 1),\n",
    "                    size=lod_size(current_lod),\n",
    "                    align_corners=False,\n",
    "                )\n",
    "            elif preferred_lod > current_lod:\n",
    "                # Unpooling\n",
    "                return tf.image.resize_bilinear(\n",
    "                    images=layer(target_layer_index, preferred_lod, current_lod + 1),\n",
    "                    size=lod_size(current_lod),\n",
    "                    align_corners=False,\n",
    "                )\n",
    "    lowest_lod = len(lod_channels) - 1\n",
    "    scores = tf.nn.xw_plus_b(\n",
    "        x=tf.reduce_mean(layer(number_of_layers - 1, lowest_lod, lowest_lod), axis=(1, 2)),\n",
    "        weights=tf.get_variable(name=\"dense_weight\", initializer=tf.random_normal_initializer(), dtype=tf.float32, shape=(lod_channels[lowest_lod], number_of_classes)),\n",
    "        biases=tf.get_variable(name=\"dense_bias\", initializer=tf.zeros_initializer(), dtype=tf.float32, shape=number_of_classes)\n",
    "    )\n",
    "    probabilities = tf.nn.softmax(logits=scores)\n",
    "    predicted_classes = tf.argmax(scores, 1)\n",
    "    predictions = {\n",
    "        'probabilities' : probabilities,\n",
    "        'scores': scores,\n",
    "        'class': predicted_classes,\n",
    "    }\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes)\n",
    "    }\n",
    "    loss = tf.losses.softmax_cross_entropy(logits=scores, onehot_labels=tf.one_hot(labels, number_of_classes))\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=f\"models/mapped-offnet{number_of_layers}\",\n",
    "    session_config=tf.ConfigProto(\n",
    "        graph_options=tf.GraphOptions(\n",
    "            optimizer_options=tf.OptimizerOptions(\n",
    "                global_jit_level=tf.OptimizerOptions.ON_2,\n",
    "                do_function_inlining=True,\n",
    "                do_constant_folding=True,\n",
    "                do_common_subexpression_elimination=True,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/mapped-offnet64', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': graph_options {\n",
      "  optimizer_options {\n",
      "    do_common_subexpression_elimination: true\n",
      "    do_constant_folding: true\n",
      "    do_function_inlining: true\n",
      "    global_jit_level: ON_2\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f391230b6a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7f39158d3a60>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn, config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(training_data).shuffle(1000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(testing_data).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6064\")\n",
    "# estimator.train(training_dataset,hooks=[hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=tf.estimator.TrainSpec(training_dataset),\n",
    "    eval_spec=tf.estimator.EvalSpec(testing_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
