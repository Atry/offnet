{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iteration_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "training_data, testing_data = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = int(np.max(testing_data[1])) + 1\n",
    "number_of_input_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_experts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features_per_layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_computing_layers = number_of_hidden_layers + number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_layers = number_of_input_channels + number_of_computing_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_number_samples_per_layer = number_of_layers # All the previous layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddings = (0, 0), (2, 2), (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = number_of_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_initializer():\n",
    "    return tf.random_normal_initializer(stddev=3.0)\n",
    "#     return tf.random_uniform_initializer(minval=-3.0, maxval=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_sample(images, offset_x, offset_y):\n",
    "    tf.assert_rank(images, 4)\n",
    "    tf.assert_rank(offset_x, 4)\n",
    "    tf.assert_rank(offset_y, 4)\n",
    "    image_shape = tf.shape(images)\n",
    "    current_batch_size = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    height = image_shape[2]\n",
    "    number_of_features = image_shape[3]\n",
    "    \n",
    "    def check_width(tensor):\n",
    "        if (tf.test.is_gpu_available()):\n",
    "            return tensor\n",
    "        else:\n",
    "            return tf.maximum(tf.minimum(tensor, width - 1), 0)\n",
    "    \n",
    "    def check_height(tensor):\n",
    "        if (tf.test.is_gpu_available()):\n",
    "            return tensor\n",
    "        else:\n",
    "            return tf.maximum(tf.minimum(tensor, height - 1), 0)\n",
    "    \n",
    "    offset_left = tf.floor(offset_x)\n",
    "    offset_top = tf.floor(offset_y)\n",
    "    tf.assert_equal(tf.shape(offset_left), image_shape)\n",
    "    tf.assert_equal(tf.shape(offset_top), image_shape)\n",
    "\n",
    "    \n",
    "    eps = 1e-7\n",
    "\n",
    "    factor_right = offset_x - offset_left + eps\n",
    "    factor_left = 1.0 + 2.0 * eps - factor_right\n",
    "    factor_bottom = offset_y - offset_top + eps\n",
    "    factor_top = 1.0 + 2.0 * eps - factor_bottom\n",
    "    \n",
    "    image_index, x_index, y_index, feature_index = tf.meshgrid(\n",
    "        tf.range(current_batch_size, dtype=tf.int32),\n",
    "        tf.range(width, dtype=tf.int32),\n",
    "        tf.range(height, dtype=tf.int32),\n",
    "        tf.range(number_of_features, dtype=tf.int32),\n",
    "        indexing='ij',\n",
    "    )\n",
    "\n",
    "    left_index = check_width(x_index + tf.cast(offset_left, tf.int32))\n",
    "    top_index = check_height(y_index + tf.cast(offset_top, tf.int32))\n",
    "\n",
    "    right_index = left_index + 1\n",
    "    bottom_index = top_index + 1\n",
    "    \n",
    "    tf.assert_rank(left_index, 4)\n",
    "    tf.assert_rank(right_index, 4)\n",
    "    tf.assert_rank(bottom_index, 4)\n",
    "    tf.assert_rank(top_index, 4)\n",
    "    \n",
    "    images_top_left = tf.gather_nd(images, tf.stack((image_index, left_index, top_index, feature_index), axis=4))\n",
    "    images_top_right = tf.gather_nd(images, tf.stack((image_index, right_index, top_index, feature_index), axis=4))\n",
    "    images_bottom_left = tf.gather_nd(images, tf.stack((image_index, left_index, bottom_index, feature_index), axis=4))\n",
    "    images_bottom_right = tf.gather_nd(images, tf.stack((image_index, right_index, bottom_index, feature_index), axis=4))\n",
    "\n",
    "    tf.assert_rank(images_top_left, 4)\n",
    "    tf.assert_rank(images_top_right, 4)\n",
    "    tf.assert_rank(images_bottom_left, 4)\n",
    "    tf.assert_rank(images_bottom_right, 4)\n",
    "\n",
    "    lerp_top = factor_left * images_top_left + factor_right * images_top_right\n",
    "    lerp_bottom = factor_left * images_bottom_left + factor_right * images_bottom_right\n",
    "    output = factor_top * lerp_top + factor_bottom * lerp_bottom\n",
    "    tf.assert_rank(output, 4)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offnet(images, number_of_features, number_of_experts=None, name=None):\n",
    "    with tf.variable_scope(name, default_name=\"offnet\"):\n",
    "        input_shape = images.shape\n",
    "        if number_of_experts is None:\n",
    "            number_of_experts = int(input_shape[0])\n",
    "        number_of_input_features = int(input_shape[4])\n",
    "        score_weight = tf.get_variable(\n",
    "            name=\"score_weight\",\n",
    "            initializer=tf.random_normal_initializer(stddev=tf.sqrt(1.0 / number_of_input_features)),\n",
    "            dtype=tf.float32,\n",
    "            shape=(number_of_experts, number_of_input_features, number_of_features)\n",
    "        )\n",
    "        offset_x_weight = tf.get_variable(\n",
    "            name=\"offset_x_weight\",\n",
    "            initializer=tf.random_normal_initializer(stddev=tf.sqrt(1.0 / number_of_input_features)),\n",
    "            dtype=tf.float32,\n",
    "            shape=(number_of_experts, number_of_input_features, number_of_features)\n",
    "        )\n",
    "        offset_y_weight = tf.get_variable(\n",
    "            name=\"offset_y_weight\",\n",
    "            initializer=tf.random_normal_initializer(stddev=tf.sqrt(1.0 / number_of_input_features)),\n",
    "            dtype=tf.float32,\n",
    "            shape=(number_of_experts, number_of_input_features, number_of_features)\n",
    "        )\n",
    "        offset_x_bias = tf.get_variable(\n",
    "            name=\"offset_x_bias\",\n",
    "            initializer=offset_initializer(),\n",
    "            dtype=tf.float32,\n",
    "            shape=(number_of_experts, 1, number_of_features),\n",
    "        )\n",
    "        offset_y_bias = tf.get_variable(\n",
    "            name=\"offset_y_bias\",\n",
    "            initializer=offset_initializer(),\n",
    "            dtype=tf.float32,\n",
    "            shape=(number_of_experts, 1,  number_of_features),\n",
    "        )\n",
    "#         def scale_initializer():\n",
    "#             return tf.sqrt(weight_scale / number_of_input_features)\n",
    "#         score_scale = tf.get_variable(\n",
    "#             name=\"score_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "#         offset_x_scale = tf.get_variable(\n",
    "#             name=\"offset_x_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "#         offset_y_scale = tf.get_variable(\n",
    "#             name=\"offset_y_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "        \n",
    "        dynamic_image_shape = tf.shape(images)\n",
    "        images_3d = tf.reshape(\n",
    "            images,\n",
    "            (\n",
    "                number_of_experts,\n",
    "                dynamic_image_shape[1] * dynamic_image_shape[2] * dynamic_image_shape[3],\n",
    "                number_of_input_features\n",
    "            )\n",
    "        )\n",
    "        def images_xw_plus_b(w, b):\n",
    "            tf.matmul(images_3d, w) + b\n",
    "        \n",
    "        def to_4d(images):\n",
    "            tf.assert_equal(tf.shape(images), (number_of_experts, dynamic_image_shape[1] * dynamic_image_shape[2] * dynamic_image_shape[3], number_of_features))\n",
    "            return tf.reshape(\n",
    "                images,\n",
    "                (\n",
    "                    number_of_experts * dynamic_image_shape[1],\n",
    "                    dynamic_image_shape[2],\n",
    "                    dynamic_image_shape[3],\n",
    "                    number_of_features\n",
    "                )\n",
    "            )\n",
    "        return tf.reshape(\n",
    "            grid_sample(\n",
    "                to_4d(tf.matmul(images_3d, score_weight)),\n",
    "                to_4d(tf.matmul(images_3d, offset_x_weight) + offset_x_bias),\n",
    "                to_4d(tf.matmul(images_3d, offset_y_weight) + offset_y_bias)\n",
    "            ),\n",
    "            (\n",
    "                number_of_experts,\n",
    "                dynamic_image_shape[1],\n",
    "                dynamic_image_shape[2],\n",
    "                dynamic_image_shape[3],\n",
    "                number_of_features\n",
    "            )\n",
    "        )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_horizontal_samples = 3\n",
    "number_of_vertical_samples = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params, config):\n",
    "    random.seed(number_of_hidden_layers)\n",
    "    padded_input = tf.expand_dims(\n",
    "        tf.expand_dims(\n",
    "            tf.pad(tf.cast(features, tf.float32) / 255.0 - 0.5, paddings),\n",
    "            axis=0\n",
    "        ),\n",
    "        axis=4\n",
    "    )\n",
    "    width = int(padded_input.shape[2])\n",
    "    height = int(padded_input.shape[3])\n",
    "    \n",
    "    layers = functools.reduce(\n",
    "        lambda layers, i: tf.concat(\n",
    "            (\n",
    "                layers,\n",
    "                tf.layers.batch_normalization(\n",
    "                    offnet(layers, number_of_features_per_layer, number_of_experts),\n",
    "                    training=mode is tf.estimator.ModeKeys.TRAIN\n",
    "                )\n",
    "            ),\n",
    "            axis=4\n",
    "        ),\n",
    "        range(number_of_hidden_layers),\n",
    "        padded_input\n",
    "    )\n",
    "    score_layers = offnet(layers, number_of_classes, number_of_experts)\n",
    "    dynamic_shape = tf.shape(layers)\n",
    "    current_batch_size = dynamic_shape[1]\n",
    "    scores = tf.reduce_mean(\n",
    "        tf.reduce_mean(\n",
    "            score_layers,\n",
    "            axis=0\n",
    "        )[\n",
    "            :,\n",
    "            int(width / (number_of_horizontal_samples + 1)):int(width * number_of_horizontal_samples / (number_of_horizontal_samples + 1)):int(width / (number_of_horizontal_samples + 1)),\n",
    "            int(height / (number_of_horizontal_samples + 1)):int(height * number_of_horizontal_samples / (number_of_horizontal_samples + 1)):int(height / (number_of_horizontal_samples + 1)),\n",
    "            :\n",
    "        ],\n",
    "        axis=(1, 2)\n",
    "    )\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits=scores)\n",
    "    predicted_classes = tf.argmax(scores, 1)\n",
    "    predictions = {\n",
    "        'probabilities' : probabilities,\n",
    "        'scores': scores,\n",
    "        'class': predicted_classes,\n",
    "    }\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(epsilon=0.1)\n",
    "    if labels is None:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    else:\n",
    "        loss = tf.losses.softmax_cross_entropy(logits=scores, onehot_labels=tf.one_hot(labels, number_of_classes))\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes)\n",
    "        }\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode=mode,\n",
    "                predictions=predictions,\n",
    "                loss=loss,\n",
    "                train_op=optimizer.minimize(loss, global_step=tf.train.get_global_step()),\n",
    "                eval_metric_ops=eval_metric_ops,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=f\"models/offnet{number_of_experts}x{number_of_features_per_layer}x{number_of_hidden_layers}\",\n",
    "    session_config=tf.ConfigProto(\n",
    "        gpu_options=tf.GPUOptions(\n",
    "            allow_growth=True,\n",
    "        ),\n",
    "        graph_options=tf.GraphOptions(\n",
    "            optimizer_options=tf.OptimizerOptions(\n",
    "                global_jit_level=tf.OptimizerOptions.ON_2,\n",
    "                do_function_inlining=True,\n",
    "                do_constant_folding=True,\n",
    "                do_common_subexpression_elimination=True,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn, config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(training_data).shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(testing_data).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6064\")\n",
    "# estimator.train(training_dataset,hooks=[hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=tf.estimator.TrainSpec(training_dataset),\n",
    "    eval_spec=tf.estimator.EvalSpec(testing_dataset, throttle_secs=1800)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.evaluate(input_fn=lambda:tf.data.Dataset.from_tensor_slices(testing_data).batch(3).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple(estimator.predict(input_fn=lambda:tf.data.Dataset.from_tensor_slices(testing_data).batch(3).take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.train(input_fn=training_dataset, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
