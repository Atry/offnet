{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iteration_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "training_data, testing_data = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = np.max(testing_data[1]).__int__() + 1\n",
    "number_of_input_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_computing_layers = number_of_hidden_layers + number_of_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_layers = number_of_input_channels + number_of_computing_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_number_samples_per_layer = number_of_layers # All the previous layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddings = (0, 0), (2, 2), (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = number_of_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_scale = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_sample_v2(images, offset_x, offset_y):\n",
    "#     tf.assert_rank(images, 4)\n",
    "#     tf.assert_rank(offset_x, 4)\n",
    "#     tf.assert_rank(offset_y, 4)\n",
    "#     image_shape = tf.shape(images)\n",
    "#     current_batch_size = image_shape[0]\n",
    "#     width = image_shape[1]\n",
    "#     height = image_shape[2]\n",
    "#     number_of_features = image_shape[3]\n",
    "    \n",
    "#     def check_width(tensor):\n",
    "#         if (tf.test.is_gpu_available()):\n",
    "#             return tensor\n",
    "#         else:\n",
    "#             return tf.maximum(tf.minimum(tensor, width - 1), 0)\n",
    "    \n",
    "#     def check_height(tensor):\n",
    "#         if (tf.test.is_gpu_available()):\n",
    "#             return tensor\n",
    "#         else:\n",
    "#             return tf.maximum(tf.minimum(tensor, height - 1), 0)\n",
    "    \n",
    "#     offset_left = tf.floor(offset_x)\n",
    "#     offset_top = tf.floor(offset_y)\n",
    "#     tf.assert_equal(tf.shape(offset_left), image_shape)\n",
    "#     tf.assert_equal(tf.shape(offset_top), image_shape)\n",
    "\n",
    "    \n",
    "#     eps = 1e-7\n",
    "\n",
    "#     factor_right = offset_x - offset_left + eps\n",
    "#     factor_left = 1.0 + 2.0 * eps - factor_right\n",
    "#     factor_bottom = offset_y - offset_top + eps\n",
    "#     factor_top = 1.0 + 2.0 * eps - factor_bottom\n",
    "    \n",
    "#     image_index, x_index, y_index, feature_index = tf.meshgrid(\n",
    "#         tf.range(current_batch_size, dtype=tf.int32),\n",
    "#         tf.range(width, dtype=tf.int32),\n",
    "#         tf.range(height, dtype=tf.int32),\n",
    "#         tf.range(number_of_features, dtype=tf.int32),\n",
    "#         indexing='ij',\n",
    "#     )\n",
    "\n",
    "#     left_index = check_width(x_index + tf.cast(offset_left, tf.int32))\n",
    "#     top_index = check_height(y_index + tf.cast(offset_top, tf.int32))\n",
    "\n",
    "#     right_index = left_index + 1\n",
    "#     bottom_index = top_index + 1\n",
    "    \n",
    "#     tf.assert_rank(left_index, 4)\n",
    "#     tf.assert_rank(right_index, 4)\n",
    "#     tf.assert_rank(bottom_index, 4)\n",
    "#     tf.assert_rank(top_index, 4)\n",
    "    \n",
    "#     images_top_left = tf.gather_nd(images, tf.stack((image_index, left_index, top_index, feature_index), axis=4))\n",
    "#     images_top_right = tf.gather_nd(images, tf.stack((image_index, right_index, top_index, feature_index), axis=4))\n",
    "#     images_bottom_left = tf.gather_nd(images, tf.stack((image_index, left_index, bottom_index, feature_index), axis=4))\n",
    "#     images_bottom_right = tf.gather_nd(images, tf.stack((image_index, right_index, bottom_index, feature_index), axis=4))\n",
    "\n",
    "#     tf.assert_rank(images_top_left, 4)\n",
    "#     tf.assert_rank(images_top_right, 4)\n",
    "#     tf.assert_rank(images_bottom_left, 4)\n",
    "#     tf.assert_rank(images_bottom_right, 4)\n",
    "\n",
    "#     lerp_top = factor_left * images_top_left + factor_right * images_top_right\n",
    "#     lerp_bottom = factor_left * images_bottom_left + factor_right * images_bottom_right\n",
    "#     output = factor_top * lerp_top + factor_bottom * lerp_bottom\n",
    "#     tf.assert_rank(output, 4)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_sample(images, offset_x, offset_y):\n",
    "    tf.assert_rank(images, 3)\n",
    "    image_shape = tf.shape(images)\n",
    "    current_batch_size = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    height = image_shape[2]\n",
    "    \n",
    "    def check_width(tensor):\n",
    "        if (tf.test.is_gpu_available()):\n",
    "            return tensor\n",
    "        else:\n",
    "            return tf.maximum(tf.minimum(tensor, width - 1), 0)\n",
    "    \n",
    "    def check_height(tensor):\n",
    "        if (tf.test.is_gpu_available()):\n",
    "            return tensor\n",
    "        else:\n",
    "            return tf.maximum(tf.minimum(tensor, height - 1), 0)\n",
    "    \n",
    "    offset_left = tf.floor(offset_x)\n",
    "    offset_top = tf.floor(offset_y)\n",
    "    tf.assert_equal(tf.shape(offset_left), image_shape)\n",
    "    tf.assert_equal(tf.shape(offset_top), image_shape)\n",
    "\n",
    "    \n",
    "    eps = 1e-7\n",
    "\n",
    "    factor_right = offset_x - offset_left + eps\n",
    "    factor_left = 1.0 + 2.0 * eps - factor_right\n",
    "    factor_bottom = offset_y - offset_top + eps\n",
    "    factor_top = 1.0 + 2.0 * eps - factor_bottom\n",
    "    \n",
    "    image_index, x_index, y_index = tf.meshgrid(\n",
    "        tf.range(current_batch_size, dtype=tf.int32),\n",
    "        tf.range(width, dtype=tf.int32),\n",
    "        tf.range(height, dtype=tf.int32),\n",
    "        indexing='ij',\n",
    "    )\n",
    "    \n",
    "    tf.assert_equal(tf.shape(image_index), image_shape)\n",
    "    tf.assert_equal(tf.shape(x_index), image_shape)\n",
    "    tf.assert_equal(tf.shape(y_index), image_shape)\n",
    "\n",
    "    \n",
    "    left_index = check_width(x_index + tf.cast(offset_left, tf.int32))\n",
    "    top_index = check_height(y_index + tf.cast(offset_top, tf.int32))\n",
    "\n",
    "    right_index = left_index + 1\n",
    "    bottom_index = top_index + 1\n",
    "    \n",
    "    tf.assert_equal(tf.shape(left_index), image_shape)\n",
    "    tf.assert_equal(tf.shape(top_index), image_shape)\n",
    "    tf.assert_equal(tf.shape(right_index), image_shape)\n",
    "    tf.assert_equal(tf.shape(bottom_index), image_shape)    \n",
    "    \n",
    "    tf.assert_rank(left_index, 3)\n",
    "    tf.assert_rank(right_index, 3)\n",
    "    tf.assert_rank(bottom_index, 3)\n",
    "    tf.assert_rank(top_index, 3)\n",
    "    \n",
    "    images_top_left = tf.gather_nd(images, tf.stack((image_index, left_index, top_index), axis=3))\n",
    "    images_top_right = tf.gather_nd(images, tf.stack((image_index, right_index, top_index), axis=3))\n",
    "    images_bottom_left = tf.gather_nd(images, tf.stack((image_index, left_index, bottom_index), axis=3))\n",
    "    images_bottom_right = tf.gather_nd(images, tf.stack((image_index, right_index, bottom_index), axis=3))\n",
    "\n",
    "    tf.assert_rank(images_top_left, 3)\n",
    "    tf.assert_rank(images_top_right, 3)\n",
    "    tf.assert_rank(images_bottom_left, 3)\n",
    "    tf.assert_rank(images_bottom_right, 3)\n",
    "\n",
    "    lerp_top = factor_left * images_top_left + factor_right * images_top_right\n",
    "    lerp_bottom = factor_left * images_bottom_left + factor_right * images_bottom_right\n",
    "    output = factor_top * lerp_top + factor_bottom * lerp_bottom\n",
    "    tf.assert_rank(output, 3)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def offnet(input_images, number_of_additional_features, name=None):\n",
    "#     \"\"\"\n",
    "#     input_images: a tensor of number_of_input_channels x batch_size x width x height\n",
    "#     \"\"\"\n",
    "#     with tf.variable_scope(name, default_name=\"offset\"):\n",
    "#         if input_images is IndexedSlices:\n",
    "#             image_shape = input_images.dense_shape\n",
    "#         else:\n",
    "#             image_shape = input_images.shape\n",
    "#         number_of_input_channels = image_shape[0]\n",
    "#         batch_size = image_shape[1]\n",
    "#         width = image_shape[2]\n",
    "#         height = image_shape[3]\n",
    "\n",
    "#         score_weight = tf.get_variable(\n",
    "#             name=\"score_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_features, number_of_input_channels)\n",
    "#         )\n",
    "#         score_bias = tf.get_variable(\n",
    "#             name=\"score_bias\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_input_channels, 1, 1, 1)\n",
    "#         )\n",
    "        \n",
    "#         offset_x_weight = tf.get_variable(\n",
    "#             name=\"offset_x_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_features, number_of_input_channels)\n",
    "#         )\n",
    "#         offset_x_bias = tf.get_variable(\n",
    "#             name=\"offset_x_bias\",\n",
    "#             initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_features, 1, 1, 1),\n",
    "#         )\n",
    "\n",
    "#         offset_y_weight = tf.get_variable(\n",
    "#             name=\"offset_y_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_features, number_of_input_channels)\n",
    "#         )\n",
    "#         offset_y_bias = tf.get_variable(\n",
    "#             name=\"offset_y_bias\",\n",
    "#             initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_features, 1, 1, 1),\n",
    "#         )\n",
    "        \n",
    "#         def indexed_sum(weight, bias):\n",
    "#             if input_images is IndexedSlices:\n",
    "#                 tf.tensordot(tf.gather(weight, input_images.indices), TODO)\n",
    "                \n",
    "# #                 input_images.values\n",
    "# #                 values_shape = tf.shape(input_images.values)\n",
    "                \n",
    "# #                 tf.sparse_matmul(\n",
    "# #                     weight,\n",
    "# #                     tf.SparseTensor(\n",
    "# #                         input_images.indices,\n",
    "# #                         tf.reshape(input_images.values, (values_shape[0], values_shape[1] * values_shape[2] * values_shape[3])),\n",
    "# #                         input_images.dense_shape,\n",
    "# #                     )\n",
    "# #                     tf.sparse_reshape(input_images)\n",
    "# #                 )\n",
    "# #                 TODO\n",
    "#             else:\n",
    "#                 tf.tensordot(weight, input_images, axes=1) + bias\n",
    "#         indexed_sum(weight, score_bias)\n",
    "#         indexed_sum(weight, score_bias)\n",
    "#         indexed_sum(weight, score_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dense_offset_layers(input_images, number_of_additional_layers, number_of_features_per_layer):\n",
    "#     with tf.variable_scope(None, default_name=\"dense_offset\"):\n",
    "#         image_shape = input_images.shape\n",
    "#         batch_size = image_shape[0]\n",
    "#         width = image_shape[1]\n",
    "#         height = image_shape[2]\n",
    "#         number_of_input_channels = image_shape[3]\n",
    "        \n",
    "#         weight_size = (number_of_additional_layers + number_of_input_channels) * (number_of_additional_layers - number_of_input_channels) // 2\n",
    "#         score_weight = tf.get_variable(\n",
    "#             name=\"score_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(weight_size, number_of_features_per_layer)\n",
    "#         )\n",
    "#         offset_x_weight = tf.get_variable(\n",
    "#             name=\"offset_x_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(weight_size, number_of_features_per_layer)\n",
    "#         )\n",
    "#         offset_y_weight = tf.get_variable(\n",
    "#             name=\"offset_y_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(weight_size, number_of_features_per_layer)\n",
    "#         )\n",
    "#         score_bias = tf.get_variable(\n",
    "#             name=\"score_bias\",\n",
    "#             initializer=tf.zeros_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_layers, 1, 1, 1, number_of_features_per_layer),\n",
    "#         )\n",
    "#         offset_x_bias = tf.get_variable(\n",
    "#             name=\"offset_x_bias\",\n",
    "#             initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_layers, 1, 1, 1, number_of_features_per_layer),\n",
    "#         )\n",
    "#         offset_y_bias = tf.get_variable(\n",
    "#             name=\"offset_y_bias\",\n",
    "#             initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_layers, 1, 1, 1, number_of_features_per_layer),\n",
    "#         )\n",
    "#         def scale_initializer():\n",
    "#             input_sizes = tf.expand_dims(\n",
    "#                 tf.expand_dims(\n",
    "#                     tf.to_float(\n",
    "#                         tf.range(number_of_input_channels, number_of_input_channels + number_of_additional_layers * number_of_features_per_layer)\n",
    "#                     ),\n",
    "#                     axis=0\n",
    "#                 ),\n",
    "#                 axis=2\n",
    "#             )\n",
    "#             broadcast_weight_scale = tf.fill((number_of_additional_layers, 1, number_of_features_per_layer), weight_scale)\n",
    "#             return tf.sqrt(broadcast_weight_scale / input_sizes)\n",
    "                \n",
    "#         score_scale = tf.get_variable(\n",
    "#             name=\"score_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "#         offset_x_scale = tf.get_variable(\n",
    "#             name=\"offset_x_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "#         offset_y_scale = tf.get_variable(\n",
    "#             name=\"offset_y_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "\n",
    "#         def score_map(i, previous_layers):\n",
    "#             next_layer_id = i * number_of_features_per_layer + number_of_input_channels\n",
    "#             tf.assert_equal(tf.shape(previous_layers)[3], next_layer_id)\n",
    "#             weight_start = (next_layer_id + number_of_input_channels) * (next_layer_id - number_of_input_channels) * number_of_features_per_layer // 2\n",
    "#             weight_end = weight_start + next_layer_id\n",
    "#             tf.assert_rank(weight_start, 0)\n",
    "#             tf.assert_none_equal(weight_start, weight_end)\n",
    "\n",
    "#             def indexed_sum(weight, bias, scale):\n",
    "#                 tf.assert_rank(weight, 2)\n",
    "#                 scale_slice = scale[i]\n",
    "#                 tf.assert_equal(tf.shape(scale_slice)[0], 1)\n",
    "#                 tf.assert_equal(tf.shape(scale_slice)[1], number_of_features_per_layer)\n",
    "#                 weight_slice = weight[weight_start:weight_end]\n",
    "#                 tf.assert_rank(weight_slice, 2)\n",
    "#                 tf.assert_equal(tf.shape(weight_slice)[0], tf.shape(previous_layers)[3])\n",
    "#                 tf.assert_equal(tf.shape(weight_slice)[1], number_of_features_per_layer)\n",
    "#                 tf.assert_rank(previous_layers, 4)\n",
    "                \n",
    "#                 tf.keras.backend.print_tensor(weight_slice * scale_slice, message=\"weight_slice\")\n",
    "                \n",
    "                \n",
    "#                 dynamic_image_shape = tf.shape(input_images)\n",
    "# #                 t = tf.random_normal((dynamic_image_shape[0], dynamic_image_shape[1], dynamic_image_shape[2], number_of_features_per_layer))\n",
    "                \n",
    "#                 t = tf.reshape(\n",
    "#                     tf.matmul(\n",
    "#                         tf.reshape(previous_layers, (dynamic_image_shape[0] * dynamic_image_shape[1] * dynamic_image_shape[2], next_layer_id)),\n",
    "#                         weight_slice\n",
    "#                     ),\n",
    "#                     (dynamic_image_shape[0], dynamic_image_shape[1], dynamic_image_shape[2], number_of_features_per_layer)\n",
    "#                 ) + bias[i]\n",
    "                \n",
    "                \n",
    "# #                 t = tf.tensordot(previous_layers, weight_slice, axes=1) + bias[i]\n",
    "                                \n",
    "#                 tf.assert_equal(tf.shape(t)[0], tf.shape(input_images)[0])\n",
    "#                 tf.assert_equal(tf.shape(t)[1], tf.shape(input_images)[1])\n",
    "#                 tf.assert_equal(tf.shape(t)[2], tf.shape(input_images)[2])\n",
    "#                 tf.assert_equal(tf.shape(t)[3], number_of_features_per_layer)\n",
    "#                 return t\n",
    "\n",
    "#             return grid_sample(\n",
    "#                 indexed_sum(score_weight, score_bias, score_scale),\n",
    "#                 indexed_sum(offset_x_weight, offset_x_bias, offset_x_scale),\n",
    "#                 indexed_sum(offset_y_weight, offset_y_bias, offset_y_scale),\n",
    "#             )\n",
    "\n",
    "#         i, output_layers = tf.while_loop(\n",
    "#             cond=lambda i, layers: i < number_of_additional_layers,\n",
    "#             body=lambda i, layers: (\n",
    "#                 i + 1,\n",
    "#                 tf.concat(\n",
    "#                     (layers, score_map(i, layers)),\n",
    "#                     3\n",
    "#                 )\n",
    "#             ),\n",
    "#             loop_vars=(0, input_images),\n",
    "#             shape_invariants=(tf.TensorShape(()), tf.TensorShape((batch_size, width, height, None)))\n",
    "#         )\n",
    "#         return output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: add a flag to disable the scale variable\n",
    "# def dense_offset_layers_v2(input_images, number_of_additional_layers, number_of_features_per_layer, name=None):\n",
    "#     with tf.variable_scope(name, default_name=\"dense_offset\"):\n",
    "#         image_shape = input_images.shape\n",
    "#         number_of_input_channels = image_shape[0]\n",
    "#         batch_size = image_shape[1]\n",
    "#         width = image_shape[2]\n",
    "#         height = image_shape[3]\n",
    "\n",
    "#         weight_size = (number_of_additional_layers + number_of_input_channels) * (number_of_additional_layers - number_of_input_channels) // 2\n",
    "#         score_weight = tf.get_variable(\n",
    "#             name=\"score_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_features_per_layer, weight_size)\n",
    "#         )\n",
    "#         offset_x_weight = tf.get_variable(\n",
    "#             name=\"offset_x_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_features_per_layer, weight_size)\n",
    "#         )\n",
    "#         offset_y_weight = tf.get_variable(\n",
    "#             name=\"offset_y_weight\",\n",
    "#             initializer=tf.random_normal_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_features_per_layer, weight_size)\n",
    "#         )\n",
    "#         score_bias = tf.get_variable(\n",
    "#             name=\"score_bias\",\n",
    "#             initializer=tf.zeros_initializer(),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_layers, number_of_features_per_layer, 1, 1, 1),\n",
    "#         )\n",
    "#         offset_x_bias = tf.get_variable(\n",
    "#             name=\"offset_x_bias\",\n",
    "#             initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_layers, number_of_features_per_layer, 1, 1, 1),\n",
    "#         )\n",
    "#         offset_y_bias = tf.get_variable(\n",
    "#             name=\"offset_y_bias\",\n",
    "#             initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "#             dtype=tf.float32,\n",
    "#             shape=(number_of_additional_layers, number_of_features_per_layer, 1, 1, 1),\n",
    "#         )\n",
    "#         def scale_initializer():\n",
    "#             input_sizes = functools.reduce(\n",
    "#                 tf.expand_dims,\n",
    "#                 range(1, 3),\n",
    "#                 tf.to_float(\n",
    "#                     tf.range(number_of_input_channels, number_of_input_channels + number_of_additional_layers)\n",
    "#                 )\n",
    "#             )\n",
    "#             broadcast_weight_scale = tf.fill((number_of_additional_layers, 1, number_of_features_per_layer), weight_scale)\n",
    "#             tf.assert_rank(broadcast_weight_scale, 3)\n",
    "#             return tf.sqrt(broadcast_weight_scale / input_sizes)\n",
    "                \n",
    "#         score_scale = tf.get_variable(\n",
    "#             name=\"score_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "#         offset_x_scale = tf.get_variable(\n",
    "#             name=\"offset_x_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "#         offset_y_scale = tf.get_variable(\n",
    "#             name=\"offset_y_scale\",\n",
    "#             initializer=scale_initializer(),\n",
    "#             dtype=tf.float32\n",
    "#         )\n",
    "\n",
    "#         def score_map(i, previous_layers):\n",
    "#             next_layer_id = i + number_of_input_channels\n",
    "#             weight_start = (next_layer_id + number_of_input_channels) * (next_layer_id - number_of_input_channels)  * number_of_features_per_layer // 2\n",
    "#             weight_end = weight_start + next_layer_id * number_of_features_per_layer\n",
    "#             tf.assert_rank(weight_start, 0)\n",
    "\n",
    "#             def indexed_sum(weight, bias, scale):\n",
    "#                 tf.assert_rank(weight, 2)\n",
    "#                 weight_slice = weight[weight_start:weight_end] * scale[i]\n",
    "\n",
    "#                 tf.assert_equal(tf.shape(weight_slice)[0], tf.shape(previous_layers)[3])\n",
    "#                 t = tf.tensordot(\n",
    "#                     weight_slice,\n",
    "#                     previous_layers,\n",
    "#                     axes=1\n",
    "#                 )\n",
    "#                 tf.assert_rank(t, 4)\n",
    "#                 tf.assert_rank(bias[i], 4)\n",
    "#                 return t + bias[i]\n",
    "\n",
    "#             return grid_sample(\n",
    "#                 indexed_sum(score_weight, score_bias, score_scale),\n",
    "#                 indexed_sum(offset_x_weight, offset_x_bias, offset_x_scale),\n",
    "#                 indexed_sum(offset_y_weight, offset_y_bias, offset_y_scale),\n",
    "#             )\n",
    "\n",
    "#         i, output_layers = tf.while_loop(\n",
    "#             cond=lambda i, layers: i < number_of_additional_layers,\n",
    "#             body=lambda i, layers: (\n",
    "#                 i + 1,\n",
    "#                 tf.concat(\n",
    "#                     (layers, score_map(i, layers)),\n",
    "#                     0\n",
    "#                 )\n",
    "#             ),\n",
    "#             loop_vars=(0, input_images),\n",
    "#             shape_invariants=(tf.TensorShape(()), tf.TensorShape((None, batch_size, width, height)))\n",
    "#         )\n",
    "#         return output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_offset_layers(padded_input, number_of_additional_layers):\n",
    "    number_of_input_channels = padded_input.shape[3].__int__()\n",
    "    number_of_layers = number_of_additional_layers + number_of_input_channels\n",
    "    dense_weight_size = (number_of_layers + number_of_input_channels) * (number_of_layers - number_of_input_channels) // 2\n",
    "    score_weight = tf.get_variable(\n",
    "        name=\"score_weight\",\n",
    "        initializer=tf.random_normal_initializer(),\n",
    "        dtype=tf.float32,\n",
    "        shape=(dense_weight_size, )\n",
    "    )\n",
    "    offset_x_weight = tf.get_variable(\n",
    "        name=\"offset_x_weight\",\n",
    "        initializer=tf.random_normal_initializer(),\n",
    "        dtype=tf.float32,\n",
    "        shape=(dense_weight_size, )\n",
    "    )\n",
    "    offset_y_weight = tf.get_variable(\n",
    "        name=\"offset_y_weight\",\n",
    "        initializer=tf.random_normal_initializer(),\n",
    "        dtype=tf.float32,\n",
    "        shape=(dense_weight_size, )\n",
    "    )\n",
    "    score_bias = tf.get_variable(\n",
    "        name=\"score_bias\",\n",
    "        initializer=tf.zeros_initializer(),\n",
    "        dtype=tf.float32,\n",
    "        shape=(number_of_layers, ),\n",
    "    )\n",
    "    offset_x_bias = tf.get_variable(\n",
    "        name=\"offset_x_bias\",\n",
    "        initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "        dtype=tf.float32,\n",
    "        shape=(number_of_layers, ),\n",
    "    )\n",
    "    offset_y_bias = tf.get_variable(\n",
    "        name=\"offset_y_bias\",\n",
    "        initializer=tf.random_uniform_initializer(minval=-3.0, maxval=3.0),\n",
    "        dtype=tf.float32,\n",
    "        shape=(number_of_layers, ),\n",
    "    )\n",
    "    score_scale = tf.get_variable(\n",
    "        name=\"score_scale\",\n",
    "        initializer=tf.sqrt(weight_scale / (tf.range(number_of_layers, dtype=tf.float32) + tf.constant(1e-10))),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    offset_x_scale = tf.get_variable(\n",
    "        name=\"offset_x_scale\",\n",
    "        initializer=tf.sqrt(weight_scale / (tf.range(number_of_layers, dtype=tf.float32) + tf.constant(1e-10))),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    offset_y_scale = tf.get_variable(\n",
    "        name=\"offset_y_scale\",\n",
    "        initializer=tf.sqrt(weight_scale / (tf.range(number_of_layers, dtype=tf.float32) + tf.constant(1e-10))),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "\n",
    "    def score_map(previous_layers, number_of_previous_layers, next_layer_id):\n",
    "        weight_start = (number_of_input_channels + next_layer_id) * (next_layer_id - number_of_input_channels) // 2\n",
    "        weight_end = weight_start + number_of_previous_layers\n",
    "        tf.assert_rank(weight_start, 0)\n",
    "\n",
    "        # TODO test if the performance improves when using SparseTensor\n",
    "        tf.assert_rank(previous_layers, 4)\n",
    "\n",
    "        def indexed_sum(weight, bias, scale):\n",
    "            tf.assert_rank(weight, 1)\n",
    "            weight_slice = weight[weight_start:weight_end] * scale[next_layer_id]\n",
    "\n",
    "            tf.assert_equal(tf.shape(weight_slice)[0], tf.shape(previous_layers)[3])\n",
    "            return tf.tensordot(\n",
    "                previous_layers,\n",
    "                weight_slice,\n",
    "                axes=1\n",
    "            ) + bias[next_layer_id]\n",
    "\n",
    "        return grid_sample(\n",
    "            indexed_sum(score_weight, score_bias, score_scale),\n",
    "            indexed_sum(offset_x_weight, offset_x_bias, offset_x_scale),\n",
    "            indexed_sum(offset_y_weight, offset_y_bias, offset_y_scale),\n",
    "        )\n",
    "\n",
    "    feature_layers, i = tf.while_loop(\n",
    "        lambda layers, i: i < number_of_layers,\n",
    "        lambda layers, i: (\n",
    "            tf.concat(\n",
    "                (\n",
    "                    layers,\n",
    "                    tf.expand_dims(\n",
    "                        score_map(\n",
    "                            layers,\n",
    "                            number_of_previous_layers=i,\n",
    "                            next_layer_id=i\n",
    "                        ),\n",
    "                        axis=3,\n",
    "                    )\n",
    "                ),\n",
    "                axis=3,\n",
    "            ),\n",
    "            i + 1\n",
    "        ),\n",
    "        (\n",
    "            padded_input,\n",
    "            tf.constant(number_of_input_channels),\n",
    "        ),\n",
    "        shape_invariants=(\n",
    "            tf.TensorShape((padded_input.shape[0], padded_input.shape[1], padded_input.shape[2], None)), \n",
    "            tf.TensorShape(())\n",
    "        )\n",
    "    )\n",
    "    tf.assert_equal(i, tf.cast(number_of_layers, tf.int32))\n",
    "\n",
    "    return feature_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params, config):\n",
    "    random.seed(number_of_hidden_layers)\n",
    "    padded_input = tf.pad(tf.cast(features, tf.float32) / 255.0 - 0.5, paddings)\n",
    "\n",
    "    layers = dense_offset_layers(\n",
    "        tf.expand_dims(padded_input, axis=3),\n",
    "        number_of_hidden_layers + number_of_classes\n",
    "    )\n",
    "    scores = layers[:, padded_input.shape[1] // 2, padded_input.shape[2] // 2, (number_of_layers - number_of_classes):number_of_layers]\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits=scores)\n",
    "    predicted_classes = tf.argmax(scores, 1)\n",
    "    predictions = {\n",
    "        'probabilities' : probabilities,\n",
    "        'scores': scores,\n",
    "        'class': predicted_classes,\n",
    "    }\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "    if labels is None:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    else:\n",
    "        loss = tf.losses.softmax_cross_entropy(logits=scores, onehot_labels=tf.one_hot(labels, number_of_classes))\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "            loss=loss,\n",
    "            train_op=optimizer.minimize(loss, global_step=tf.train.get_global_step()),\n",
    "            eval_metric_ops=eval_metric_ops,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=f\"models/tmpoffnet{number_of_hidden_layers}\",\n",
    "    session_config=tf.ConfigProto(\n",
    "        gpu_options=tf.GPUOptions(\n",
    "            allow_growth=True,\n",
    "        ),\n",
    "        graph_options=tf.GraphOptions(\n",
    "            optimizer_options=tf.OptimizerOptions(\n",
    "                global_jit_level=tf.OptimizerOptions.ON_2,\n",
    "                do_function_inlining=True,\n",
    "                do_constant_folding=True,\n",
    "                do_common_subexpression_elimination=True,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'models/tmpoffnet25', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    do_common_subexpression_elimination: true\n",
      "    do_constant_folding: true\n",
      "    do_function_inlining: true\n",
      "    global_jit_level: ON_2\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff141a0bb38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7ff1bc037ae8>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn, config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(training_data).shuffle(1000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(testing_data).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6064\")\n",
    "# estimator.train(training_dataset,hooks=[hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert a TensorShape to dtype: <dtype: 'float32'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-920ac3c665ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0meval_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    437\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m   \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    517\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m           hooks=train_hooks)\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m       \u001b[0;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 856\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e7d688d69902>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode, params, config)\u001b[0m\n\u001b[1;32m      5\u001b[0m     layers = dense_offset_layers(\n\u001b[1;32m      6\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mnumber_of_hidden_layers\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumber_of_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnumber_of_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumber_of_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-6dbab695b8c7>\u001b[0m in \u001b[0;36mdense_offset_layers\u001b[0;34m(padded_input, number_of_additional_layers)\u001b[0m\n\u001b[1;32m     41\u001b[0m     score_scale = tf.get_variable(\n\u001b[1;32m     42\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"score_scale\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_scale\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     )\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[1;32m   1311\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Range\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m     \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"limit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"delta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1012\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/project-root/envs/gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_dimension_tensor_conversion_function\u001b[0;34m(d, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot convert a TensorShape to dtype: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a TensorShape to dtype: <dtype: 'float32'>"
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=tf.estimator.TrainSpec(training_dataset),\n",
    "    eval_spec=tf.estimator.EvalSpec(testing_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.evaluate(input_fn=lambda:tf.data.Dataset.from_tensor_slices(testing_data).batch(3).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple(estimator.predict(input_fn=lambda:tf.data.Dataset.from_tensor_slices(testing_data).batch(3).take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.train(input_fn=training_dataset, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
